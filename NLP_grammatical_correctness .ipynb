{"cells":[{"cell_type":"code","execution_count":null,"id":"afc94950","metadata":{"scrolled":false,"id":"afc94950","outputId":"a07fc22e-68c3-4841-92c9-30f117baec12"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package dependency_treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package dependency_treebank is already up-to-date!\n","/Users/shwetaparihar/anaconda3/lib/python3.11/site-packages/nltk/parse/dependencygraph.py:376: UserWarning: The graph doesn't contain a node that depends on the root element.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy: 82.00%\n"]}],"source":["import pandas as pd\n","import os\n","from pathlib import Path\n","import string\n","# !pip install pyspellchecker\n","from spellchecker import SpellChecker\n","\n","\n","\n","# For C-iii ==================START==================\n","import nltk\n","from nltk.parse import DependencyGraph\n","\n","# Download the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('dependency_treebank')\n","# For C-iii ===================END=================\n","\n","\n","\n","# Function to read text from file\n","def read_text_file(filename):\n","    filename = str(Path().absolute()) + '/essays_dataset/essays/' + filename\n","    try:\n","        with open(filename, 'r') as file:\n","            content = file.read()\n","        return content\n","    except FileNotFoundError:\n","        return None\n","\n","\n","# Function to count sentences\n","def count_sentences(text):\n","    # Split text into sentences based on \"\\n\", \"\\t\", and \".\"\n","    sentences = [sentence.strip() for sentence in text.replace('\\n', '\\t').split('\\t')]\n","    sentences = [sentence.strip() for s in sentences for sentence in s.split('.')]\n","    # Remove empty strings resulting from extra \"\\t\", \"\\n\" or \".\"\n","    sentences = [sentence for sentence in sentences if sentence]\n","    sentence_count = 0\n","    # Count the finite verbs:\n","    for sentence in sentences:\n","        count = 0\n","        # Tokenize the sentence into words\n","        words = word_tokenize(sentence)\n","\n","        # Tag the words with their part-of-speech (POS)\n","        tagged_words = pos_tag(words)\n","\n","        # Initialize counters\n","        finite_verb_count = 0\n","        coordinate_clause = False\n","        subordinate_clause = False\n","\n","        # Check for coordinate or subordinate clauses\n","        for i, (word, pos) in enumerate(tagged_words):\n","            if pos == 'CC' and i > 0 and i < len(tagged_words) - 1:\n","                coordinate_clause = True\n","            elif pos in ['IN', 'DT', 'WDT'] and i > 0 and i < len(tagged_words) - 1:\n","                subordinate_clause = True\n","\n","        # Count the number of finite verbs\n","        for word, pos in tagged_words:\n","            if pos.startswith('V') and pos != 'VBG':\n","                finite_verb_count += 1\n","\n","        if coordinate_clause == False and subordinate_clause == False:\n","            count = finite_verb_count\n","        else:\n","            count = 1\n","\n","        sentence_count += count\n","\n","\n","    return sentence_count\n","\n","\n","\n","# Function to count words\n","def count_words(text):\n","    # Split text into words based on whitespace, full stop, newline, or tab\n","    words = text.replace('\\n', ' ').replace('\\t', ' ').replace('.', ' ').replace('?', ' ').replace(',', ' ').replace('!', ' ').split()\n","    # Count the number of words\n","    return len(words)\n","\n","\n","## Function to count spelling mistakes\n","def count_spelling_mistakes(text):\n","    # Remove punctuation marks\n","    for punctuation in string.punctuation:\n","        text = text.replace(punctuation, ' ')\n","    # Initialize SpellChecker\n","    spell = SpellChecker()\n","    # Find misspelled words\n","    misspelled = spell.unknown(text.split())\n","    # Count the number of misspelled words\n","    num_misspelled = len(misspelled)\n","    # Return both the count and the list of misspelled words\n","    return num_misspelled, list(misspelled)\n","\n","\n","# Define a function to scale the values between 0 and 4\n","def scale_values_0_4(value, min_val, max_val):\n","    scaled_value = ((value - min_val) / (max_val - min_val)) * 4\n","    return round(scaled_value, 2)\n","\n","\n","# Define a function to scale the values between 1 and 5\n","def scale_values_1_5(value, min_val, max_val):\n","    scaled_value = ((value - min_val) / (max_val - min_val)) * 4 + 1\n","    return round(scaled_value, 2)\n","\n","\n","\n","\n","# For C-iii ==================START==================\n","\n","\n","# Define a function to scale the values between 1 and 5\n","def reverse_scale_values_1_5(value, min_val, max_val):\n","    scaled_value = ((max_val - value) / (max_val - min_val)) * 4 + 1\n","    return round(scaled_value, 2)\n","\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    #print(\"Sentence:\", sentence)\n","\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","    #print(\"Tokens:\", tokens)\n","\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","    #print(\"POS Tags:\", pos_tags)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if not is_main_sentence_formed_properly(pos_tags):\n","        mistake_count += 1\n","\n","\n","    # Check for missing constituents\n","    if not are_constituents_formed_properly(pos_tags):\n","        mistake_count += 1\n","\n","    # Check for subordinating conjunctions\n","    if not is_subordinating_conjunction_correct(pos_tags):\n","        mistake_count += 1\n","\n","    # Check for verb agreement and tense consistency\n","    if not is_verb_agreement_and_tense_consistent(pos_tags):\n","        mistake_count += 1\n","\n","    # Check for conjunction usage\n","    if not is_conjunction_usage_correct(pos_tags):\n","        mistake_count += 1\n","\n","    # Check for plurality agreement of noun with verb\n","    if not is_plural_singular_agreement_correct(pos_tags):\n","        mistake_count += 1\n","\n","\n","\n","\n","#==================\n","\n","\n","    # Check for missing constituents\n","    if not is_subject_verb_agreement_correct(pos_tags):\n","        mistake_count += 1\n","\n","    # Check for subordinating conjunctions\n","    if not is_pronoun_reference_clear(pos_tags):\n","        mistake_count += 1\n","\n","    # Check for verb agreement and tense consistency\n","    if not is_parallel_structure_correct(sentence):\n","        mistake_count += 1\n","\n","    # Check for conjunction usage\n","    if not contains_sentence_fragment(sentence):\n","        mistake_count += 1\n","\n","    # Check for plurality agreement of noun with verb\n","    if not is_conjunction_usage_correct(pos_tags):\n","        mistake_count += 1\n","\n","    # Check for missing constituents\n","    if not is_consistency_in_voice_and_perspective_correct(pos_tags):\n","        mistake_count += 1\n","\n","\n","#==================\n","\n","\n","\n","    return mistake_count\n","\n","# Function to check if main sentence formation is proper\n","def is_main_sentence_formed_properly(pos_tags):\n","    # Check if the sentence starts with a valid word\n","    first_word_tag = pos_tags[0][1]\n","    if first_word_tag in ['VB', 'VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Verbs\n","        return False\n","\n","    # Check for negation adverb before the main verb\n","    for i in range(1, len(pos_tags)):\n","        if pos_tags[i][1] == 'VB' and pos_tags[i-1][1] == 'RB' and pos_tags[i-1][0].lower() == 'not':\n","            return False\n","\n","    return True\n","\n","\n","\n","# Function to check if constituents are formed properly\n","def are_constituents_formed_properly(pos_tags):\n","    # Check for missing determiners in noun phrases\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'NN' and (i == 0 or pos_tags[i-1][1] != 'DT'):\n","            return False\n","    return True\n","\n","# Function to check if subordinating conjunction is used correctly\n","def is_subordinating_conjunction_correct(pos_tags):\n","    subordinating_conjunctions = ['when', 'although', 'if', 'because']\n","    for word, tag in pos_tags:\n","        if word.lower() in subordinating_conjunctions:\n","            # Check if the corresponding clause is finite or includes a gerund\n","            if tag not in ['VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Finite verbs or gerunds\n","                return False\n","    return True\n","\n","# Function to check if verb agreement and tense consistency are correct\n","def is_verb_agreement_and_tense_consistent(pos_tags):\n","    for i in range(len(pos_tags)):\n","        word, tag = pos_tags[i]\n","        if tag in ['VBZ', 'VBP', 'VBD', 'VBN']:  # Verbs in non-base form\n","            if i == 0 or (pos_tags[i-1][1] != 'PRP' and pos_tags[i-1][1] != 'NN'):  # Verb is not preceded by a personal pronoun or noun\n","                return False\n","    return True\n","\n","# Function to check if conjunction usage is correct\n","def is_conjunction_usage_correct(pos_tags):\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'CC':  # Conjunction\n","            if i == 0 or i == len(pos_tags) - 1:  # Conjunction appears at the beginning or end of the sentence\n","                return False\n","    return True\n","\n","# Function to check if there is plural/singular agreement between noun and verb\n","def is_plural_singular_agreement_correct(pos_tags):\n","    # Find the index of the first verb in the sentence\n","    verb_index = next((i for i, (word, tag) in enumerate(pos_tags) if tag.startswith('VB')), None)\n","    if verb_index is not None:\n","        # Find the index of the first noun occurring before the verb\n","        noun_index = next((i for i in range(verb_index) if pos_tags[i][1].startswith('NN')), None)\n","        if noun_index is not None:\n","            # Check if the noun and verb agree in plurality\n","            noun_tag = pos_tags[noun_index][1]\n","            verb_tag = pos_tags[verb_index][1]\n","            if noun_tag.endswith('S') and not verb_tag.endswith('S'):  # Noun is plural, but verb is singular\n","                return False\n","            elif not noun_tag.endswith('S') and verb_tag.endswith('S'):  # Noun is singular, but verb is plural\n","                return False\n","    return True\n","\n","\n","\n","\n","#==================\n","\n","\n","# Function to check subject-verb agreement\n","def is_subject_verb_agreement_correct(pos_tags):\n","    for i in range(len(pos_tags)):\n","        word, tag = pos_tags[i]\n","        if tag.startswith('VB') and i > 0:\n","            prev_word, prev_tag = pos_tags[i-1]\n","            if prev_tag.startswith('NN') and prev_tag != 'NNP':  # Check if preceding word is a noun\n","                return False\n","    return True\n","\n","# Function to check pronoun reference\n","def is_pronoun_reference_clear(pos_tags):\n","    pronouns = {'PRP', 'PRP$', 'WP', 'WP$'}\n","    for i in range(len(pos_tags)):\n","        word, tag = pos_tags[i]\n","        if tag in pronouns and i > 0:\n","            prev_word, prev_tag = pos_tags[i-1]\n","            if prev_tag.startswith('NN'):  # Check if preceding word is a noun\n","                return True\n","    return False\n","\n","# Function to check parallel structure\n","def is_parallel_structure_correct(sentence):\n","    # Example: \"She likes swimming, hiking, and to ride horses\"\n","    if ', and' in sentence or ', or' in sentence:\n","        return False\n","    return True\n","\n","# Function to check for sentence fragments\n","def contains_sentence_fragment(sentence):\n","    if sentence.endswith(('.', '!', '?')):  # Check if sentence ends with a punctuation mark\n","        return False\n","    return True\n","\n","\n","# Function to check conjunction usage\n","def is_conjunction_usage_correct(pos_tags):\n","    for i in range(len(pos_tags)):\n","        word, tag = pos_tags[i]\n","        if word.lower() in {'but', 'and', 'or', 'yet', 'so', 'nor'} and i > 0:\n","            prev_word, prev_tag = pos_tags[i-1]\n","            if prev_tag != '.':\n","                return False\n","    return True\n","\n","# Function to check consistency in voice and perspective\n","def is_consistency_in_voice_and_perspective_correct(pos_tags):\n","    perspective_tags = {'PRP', 'PRP$', 'WP', 'WP$'}\n","    first_person_tags = {'PRP', 'PRP$'}  # First-person perspective tags\n","    found_perspective_tag = False\n","    for word, tag in pos_tags:\n","        if tag in perspective_tags:\n","            found_perspective_tag = True\n","            if tag in first_person_tags:\n","                return False  # Inconsistent use of perspective\n","    return found_perspective_tag  # No perspective tag found or consistent perspective usage\n","\n","\n","#==================\n","\n","\n","\n","\n","\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","\n","    essay_cleaned = essay.replace('\\n', ' ').replace('\\t', ' ')\n","\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay_cleaned)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    return total_mistakes, round(total_mistakes/len(sentences),2)\n","\n","\n","\n","def calc_pred(x):\n","    if x > 11.9:\n","        return 'high'\n","    else:\n","        return 'low'\n","\n","\n","\n","# For C-iii =================END===================\n","\n","\n","def main():\n","\n","    curr_dir_path = str(Path().absolute())\n","    comp_path = curr_dir_path +'/essays_dataset/index.csv'\n","    #    df = pd.read_csv(\"/essays_dataset/index.csv\", delimiter=\";\", encoding=\"utf-8\")\n","    #    df['num_sentences'] = None\n","    df = pd.read_csv(comp_path, delimiter=\";\", encoding=\"utf-8\")\n","    df['content'] = df['filename'].apply(read_text_file)\n","\n","    # Counting total sentences in essay\n","    df['num_sentences'] = df['content'].apply(count_sentences)\n","\n","    # Counting total words in essay\n","    df['num_words'] = df['content'].apply(count_words)\n","\n","    # Counting total spelling mistakes in essay\n","    df['num_spelling_mistakes'], df['misspelled_words_list'] = zip(*df['content'].apply(count_spelling_mistakes))\n","\n","    # Counting spelling mistakes per word - (if essay is only 1 sentence, then fewer spelling mistakes is not necessarily a good score)\n","    df['spelling_mistakes_per_word'] = round(df['num_spelling_mistakes'] / df['num_words'],2)\n","\n","    # Scale the specified columns between scores 1 to 5\n","    columns_to_scale = ['num_sentences', 'num_words']\n","    for col in columns_to_scale:\n","        min_val = df[col].min()\n","        max_val = df[col].max()\n","        df[col + '_score'] = df[col].apply(lambda x: scale_values_1_5(x, min_val, max_val))\n","\n","    # Scale the specified columns between scores 0 to 4\n","    min_val = df['spelling_mistakes_per_word'].min()\n","    max_val = df['spelling_mistakes_per_word'].max()\n","    df['spelling_mistakes' + '_score'] = df['spelling_mistakes_per_word'].apply(lambda x: scale_values_0_4(x, min_val, max_val))\n","\n","    # Create final column SCORE_a with the average of 'num_sentences' and 'num_words'\n","    df['SCORE_a'] = (df['num_sentences_score'] + df['num_words_score']) / 2\n","\n","    # Create final columns SCORE_b\n","    df['SCORE_b'] = df['spelling_mistakes_score']\n","\n","\n","\n","    # For C-iii ==================START==================\n","\n","\n","    # Calculate Syntactic well-formedness (c.iii)\n","    df[['syntax_mistakes', 'syntax_mistakes_per_sent']] = df['content'].apply(lambda x: pd.Series(count_mistakes_in_essay(x)))\n","\n","    # Scale the specified columns between scores 1 to 5\n","    min_val = df['syntax_mistakes_per_sent'].min()\n","    max_val = df['syntax_mistakes_per_sent'].max()\n","    df['SCORE_ciii'] = df['syntax_mistakes_per_sent'].apply(lambda x: reverse_scale_values_1_5(x, min_val, max_val))\n","\n","    df['FINAL_SCORE'] = 2 * df['SCORE_a'] - df['SCORE_b'] + 2 * df['SCORE_ciii']\n","    df['pred'] = df['FINAL_SCORE'].apply(lambda x: calc_pred(x))\n","\n","    accuracy = (df['grade'] == df['pred']).mean() * 100\n","\n","    print(\"Accuracy: {:.2f}%\".format(accuracy))\n","\n","\n","    # For C-iii ===================END=================\n","\n","    df_comp = df[['filename','content','num_sentences','num_words','num_spelling_mistakes','syntax_mistakes','syntax_mistakes_per_sent','SCORE_a','SCORE_b','SCORE_ciii','FINAL_SCORE','pred','grade']]\n","    # # CSV file for viewing analysis fields and scores - saved in current directory\n","    # df.to_csv(curr_dir_path + \"/Final_df.csv\", index=False)\n","\n","    df_comp.head(20)\n","\n","main()"]},{"cell_type":"code","execution_count":null,"id":"66e0b544","metadata":{"id":"66e0b544","outputId":"02f84f30-42fe-4bfd-9a29-e84097767328"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SCORE_a</th>\n","      <th>SCORE_b</th>\n","      <th>SCORE_ciii</th>\n","      <th>grade</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2.800</td>\n","      <td>0.26</td>\n","      <td>2.43</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.200</td>\n","      <td>0.77</td>\n","      <td>4.28</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.410</td>\n","      <td>0.13</td>\n","      <td>3.02</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.960</td>\n","      <td>2.06</td>\n","      <td>3.68</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.660</td>\n","      <td>0.77</td>\n","      <td>2.00</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>3.030</td>\n","      <td>0.00</td>\n","      <td>3.80</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>2.165</td>\n","      <td>0.77</td>\n","      <td>2.73</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>3.305</td>\n","      <td>0.00</td>\n","      <td>2.45</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>3.260</td>\n","      <td>0.26</td>\n","      <td>4.24</td>\n","      <td>high</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>4.335</td>\n","      <td>0.26</td>\n","      <td>2.74</td>\n","      <td>high</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 4 columns</p>\n","</div>"],"text/plain":["    SCORE_a  SCORE_b  SCORE_ciii grade\n","0     2.800     0.26        2.43   low\n","1     2.200     0.77        4.28   low\n","2     3.410     0.13        3.02  high\n","3     1.960     2.06        3.68   low\n","4     1.660     0.77        2.00   low\n","..      ...      ...         ...   ...\n","95    3.030     0.00        3.80  high\n","96    2.165     0.77        2.73   low\n","97    3.305     0.00        2.45  high\n","98    3.260     0.26        4.24  high\n","99    4.335     0.26        2.74  high\n","\n","[100 rows x 4 columns]"]},"execution_count":200,"metadata":{},"output_type":"execute_result"}],"source":["df_final = df[['SCORE_a','SCORE_b','SCORE_ciii','grade']]\n","df_final"]},{"cell_type":"code","execution_count":null,"id":"da517758","metadata":{"id":"da517758"},"outputs":[],"source":["# For ML Algorithms\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","\n","# Split the data into features (X) and target variable (y)\n","x = df_final.drop('grade', axis = 1)  # Assuming 'target_column' is the name of the target variable\n","y = df_final['grade']\n","\n","# Split the data into train and test sets with stratification\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 42)\n"]},{"cell_type":"code","execution_count":null,"id":"ce588c3a","metadata":{"id":"ce588c3a","outputId":"8385a276-92e8-4190-a50f-81a34a4de84e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SCORE_a</th>\n","      <th>SCORE_b</th>\n","      <th>SCORE_ciii</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>39</th>\n","      <td>3.905</td>\n","      <td>0.13</td>\n","      <td>3.59</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.960</td>\n","      <td>2.06</td>\n","      <td>3.68</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1.690</td>\n","      <td>0.90</td>\n","      <td>2.95</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>1.565</td>\n","      <td>0.65</td>\n","      <td>2.12</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>2.110</td>\n","      <td>0.39</td>\n","      <td>3.43</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>3.295</td>\n","      <td>0.39</td>\n","      <td>2.74</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>2.915</td>\n","      <td>0.39</td>\n","      <td>4.40</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>2.030</td>\n","      <td>0.65</td>\n","      <td>2.43</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>3.140</td>\n","      <td>0.52</td>\n","      <td>3.58</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>3.355</td>\n","      <td>0.00</td>\n","      <td>3.57</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>80 rows × 3 columns</p>\n","</div>"],"text/plain":["    SCORE_a  SCORE_b  SCORE_ciii\n","39    3.905     0.13        3.59\n","3     1.960     2.06        3.68\n","13    1.690     0.90        2.95\n","27    1.565     0.65        2.12\n","30    2.110     0.39        3.43\n","..      ...      ...         ...\n","42    3.295     0.39        2.74\n","80    2.915     0.39        4.40\n","65    2.030     0.65        2.43\n","52    3.140     0.52        3.58\n","57    3.355     0.00        3.57\n","\n","[80 rows x 3 columns]"]},"execution_count":202,"metadata":{},"output_type":"execute_result"}],"source":["x_train"]},{"cell_type":"code","execution_count":null,"id":"e35cf3d4","metadata":{"id":"e35cf3d4","outputId":"a94180e2-1ce0-479e-d052-9db1b1987999"},"outputs":[{"name":"stdout","output_type":"stream","text":["Naive Bayes Accuracy: 1.0\n","Precision: 1.0\n","Recall: 1.0\n","F1-score: 1.0\n"]}],"source":["# Naive Bayes ALgorithm\n","\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Initialize the Naive Bayes classifier\n","nb_classifier = GaussianNB()\n","\n","# Train the classifier on the training data\n","nb_classifier.fit(x_train, y_train)\n","\n","# Make predictions on the test data\n","nb_predictions = nb_classifier.predict(x_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, nb_predictions)\n","print(\"Naive Bayes Accuracy:\", accuracy)\n","\n","# Calculate precision, recall, and F1-score\n","# Adjust pos_label according to your target variable\n","precision = precision_score(y_test, nb_predictions, pos_label='high')\n","recall = recall_score(y_test, nb_predictions, pos_label='high')\n","f1 = f1_score(y_test, nb_predictions, pos_label='high')\n","\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-score:\", f1)"]},{"cell_type":"code","execution_count":null,"id":"80d34246","metadata":{"id":"80d34246","outputId":"0933d4b5-0cbd-42b3-955b-b1dff8d60ac8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression Accuracy: 1.0\n","Precision: 1.0\n","Recall: 1.0\n","F1-score: 1.0\n"]}],"source":["# Logistic Regression\n","\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","\n","# Initialize the logistic regression model\n","logreg_model = LogisticRegression()\n","\n","# Train the model\n","logreg_model.fit(x_train, y_train)\n","\n","# Predict on the test set\n","y_pred = logreg_model.predict(x_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Logistic Regression Accuracy:\", accuracy)\n","\n","# Calculate precision, recall, and F1-score\n","# Adjust pos_label according to your target variable\n","precision = precision_score(y_test, y_pred, pos_label='high')\n","recall = recall_score(y_test, y_pred, pos_label='high')\n","f1 = f1_score(y_test, y_pred, pos_label='high')\n","\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-score:\", f1)"]},{"cell_type":"code","execution_count":null,"id":"bb85aaba","metadata":{"id":"bb85aaba","outputId":"b96569c5-0f56-4057-fde9-c5b724bbb396"},"outputs":[{"name":"stdout","output_type":"stream","text":["Multilayer Perceptron Accuracy: 1.0\n","Precision: 1.0\n","Recall: 1.0\n","F1-score: 1.0\n"]},{"name":"stderr","output_type":"stream","text":["/Users/shwetaparihar/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}],"source":["# MLP Classifier\n","\n","import pandas as pd\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Initialize the MLPClassifier\n","mlp_classifier = MLPClassifier()\n","\n","# Train the classifier\n","mlp_classifier.fit(x_train, y_train)\n","\n","# Predict on the test set\n","mlp_pred = mlp_classifier.predict(x_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, mlp_pred)\n","print(\"Multilayer Perceptron Accuracy:\", accuracy)\n","\n","# Calculate precision, recall, and F1-score\n","# Adjust pos_label according to your target variable\n","precision = precision_score(y_test, mlp_pred, pos_label='high')\n","recall = recall_score(y_test, mlp_pred, pos_label='high')\n","f1 = f1_score(y_test, mlp_pred, pos_label='high')\n","\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-score:\", f1)"]},{"cell_type":"code","execution_count":null,"id":"2efb167b","metadata":{"id":"2efb167b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"bdd2a318","metadata":{"id":"bdd2a318","outputId":"1eb592be-f06d-4a0a-d4b5-00dc8e270175"},"outputs":[{"name":"stdout","output_type":"stream","text":["============================\n","This is an important aspect of today time.\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","============================\n","This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","Error: Plurality agreement of noun with verb is incorrect\n","============================\n","Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","============================\n","To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","============================\n","More people go to this program television to talk about your problem, that is very radicate in my nation.\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","Error: Plurality agreement of noun with verb is incorrect\n","============================\n","The modern society rappresented the perfect ambient to influenced the minds of all the person.\n","Error: Constituents are not formed properly\n","============================\n","In my self is present the reasons of this statement, that is one of the problem of the life.\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","============================\n","But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Conjunction usage is incorrect\n","Error: Plurality agreement of noun with verb is incorrect\n","============================\n","Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","============================\n","But to explain all the aspect about this argoment is very inportant to illustre any examples.\n","Error: Conjunction usage is incorrect\n","============================\n","The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","============================\n","This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","============================\n","The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","============================\n","The my request is that the new politics discuss about this problem.\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","Length: 14\n","Total mistakes in the essay: 33\n"]},{"data":{"text/plain":["33"]},"execution_count":126,"metadata":{},"output_type":"execute_result"}],"source":["# Define a function to scale the values between 1 and 5\n","def reverse_scale_values_1_5(value, min_val, max_val):\n","    scaled_value = ((max_val - value) / (max_val - min_val)) * 4 + 1\n","    return round(scaled_value, 2)\n","\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    #print(\"Sentence:\", sentence)\n","\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","    #print(\"Tokens:\", tokens)\n","\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","    #print(\"POS Tags:\", pos_tags)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if not is_main_sentence_formed_properly(pos_tags):\n","        print(\"Error: Main sentence formation is not proper\")\n","        mistake_count += 1\n","\n","\n","\n","    # Check for missing constituents\n","    if not are_constituents_formed_properly(pos_tags):\n","        print(\"Error: Constituents are not formed properly\")\n","        mistake_count += 1\n","\n","    # Check for subordinating conjunctions\n","    if not is_subordinating_conjunction_correct(pos_tags):\n","        print(\"Error: Subordinating conjunction is used incorrectly\")\n","        mistake_count += 1\n","\n","    # Check for verb agreement and tense consistency\n","    if not is_verb_agreement_and_tense_consistent(pos_tags):\n","        print(\"Error: Verb agreement and tense consistency issue\")\n","        mistake_count += 1\n","\n","    # Check for conjunction usage\n","    if not is_conjunction_usage_correct(pos_tags):\n","        print(\"Error: Conjunction usage is incorrect\")\n","        mistake_count += 1\n","\n","    # Check for plurality agreement of noun with verb\n","    if not is_plural_singular_agreement_correct(pos_tags):\n","        print(\"Error: Plurality agreement of noun with verb is incorrect\")\n","        mistake_count += 1\n","\n","    return mistake_count\n","\n","# Function to check if main sentence formation is proper\n","def is_main_sentence_formed_properly(pos_tags):\n","    # Check if the sentence starts with a valid word\n","    first_word_tag = pos_tags[0][1]\n","    if first_word_tag in ['VB', 'VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Verbs\n","        return False\n","\n","    # Check for negation adverb before the main verb\n","    for i in range(1, len(pos_tags)):\n","        if pos_tags[i][1] == 'VB' and pos_tags[i-1][1] == 'RB' and pos_tags[i-1][0].lower() == 'not':\n","            return False\n","\n","    return True\n","\n","\n","\n","# Function to check if constituents are formed properly\n","def are_constituents_formed_properly(pos_tags):\n","    # Check for missing determiners in noun phrases\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'NN' and (i == 0 or pos_tags[i-1][1] != 'DT'):\n","            return False\n","    return True\n","\n","# Function to check if subordinating conjunction is used correctly\n","def is_subordinating_conjunction_correct(pos_tags):\n","    subordinating_conjunctions = ['when', 'although', 'if', 'because']\n","    for word, tag in pos_tags:\n","        if word.lower() in subordinating_conjunctions:\n","            # Check if the corresponding clause is finite or includes a gerund\n","            if tag not in ['VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Finite verbs or gerunds\n","                return False\n","    return True\n","\n","# Function to check if verb agreement and tense consistency are correct\n","def is_verb_agreement_and_tense_consistent(pos_tags):\n","    for i in range(len(pos_tags)):\n","        word, tag = pos_tags[i]\n","        if tag in ['VBZ', 'VBP', 'VBD', 'VBN']:  # Verbs in non-base form\n","            if i == 0 or (pos_tags[i-1][1] != 'PRP' and pos_tags[i-1][1] != 'NN'):  # Verb is not preceded by a personal pronoun or noun\n","                return False\n","    return True\n","\n","# Function to check if conjunction usage is correct\n","def is_conjunction_usage_correct(pos_tags):\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'CC':  # Conjunction\n","            if i == 0 or i == len(pos_tags) - 1:  # Conjunction appears at the beginning or end of the sentence\n","                return False\n","    return True\n","\n","# Function to check if there is plural/singular agreement between noun and verb\n","def is_plural_singular_agreement_correct(pos_tags):\n","    # Find the index of the first verb in the sentence\n","    verb_index = next((i for i, (word, tag) in enumerate(pos_tags) if tag.startswith('VB')), None)\n","    if verb_index is not None:\n","        # Find the index of the first noun occurring before the verb\n","        noun_index = next((i for i in range(verb_index) if pos_tags[i][1].startswith('NN')), None)\n","        if noun_index is not None:\n","            # Check if the noun and verb agree in plurality\n","            noun_tag = pos_tags[noun_index][1]\n","            verb_tag = pos_tags[verb_index][1]\n","            if noun_tag.endswith('S') and not verb_tag.endswith('S'):  # Noun is plural, but verb is singular\n","                return False\n","            elif not noun_tag.endswith('S') and verb_tag.endswith('S'):  # Noun is singular, but verb is plural\n","                return False\n","    return True\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","\n","    essay_cleaned = essay.replace('\\n', ' ').replace('\\t', ' ')\n","\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay_cleaned)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        print('============================')\n","        print(sentence)\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    # Print total sentences in the essay\n","    print(\"Length:\", len(sentences))\n","\n","    # Print total mistakes in the essay\n","    print(\"Total mistakes in the essay:\", total_mistakes)\n","\n","    return total_mistakes\n","\n","\n","essay = '''This is an important aspect of today time.\n","This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n","Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n","To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n","More people go to this program television to talk about your problem, that is very radicate in my nation.\n","The modern society rappresented the perfect ambient to influenced the minds of all the person.\n","In my self is present the reasons of this statement, that is one of the problem of the life.\n","But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n","Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n","But to explain all the aspect about this argoment is very inportant to illustre any examples.\n","The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n","This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n","The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n","The my request is that the new politics discuss about this problem.\n","'''\n","\n","count_mistakes_in_essay(essay)"]},{"cell_type":"code","execution_count":null,"id":"6d06db4a","metadata":{"id":"6d06db4a"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"055a2452","metadata":{"id":"055a2452"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"115b64d2","metadata":{"id":"115b64d2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9458824a","metadata":{"id":"9458824a"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"059d7ceb","metadata":{"id":"059d7ceb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"63150bbb","metadata":{"id":"63150bbb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"cdefb527","metadata":{"id":"cdefb527","outputId":"d3b88976-913c-4962-fadf-044c50f231aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["14\n"]}],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","\n","def count_finite_verbs(sentence):\n","    # Tokenize the sentence into words\n","    words = word_tokenize(sentence)\n","\n","    # Tag the words with their part-of-speech (POS)\n","    tagged_words = pos_tag(words)\n","\n","    # Initialize counters\n","    finite_verb_count = 0\n","    coordinate_clause = False\n","    subordinate_clause = False\n","\n","    # Check for coordinate or subordinate clauses\n","    for i, (word, pos) in enumerate(tagged_words):\n","        if pos == 'CC' and i > 0 and i < len(tagged_words) - 1:\n","            coordinate_clause = True\n","        elif pos in ['IN', 'DT', 'WDT'] and i > 0 and i < len(tagged_words) - 1:\n","            subordinate_clause = True\n","\n","    # Count the number of finite verbs\n","    for word, pos in tagged_words:\n","        if pos.startswith('V') and pos != 'VBG':\n","            finite_verb_count += 1\n","\n","    return finite_verb_count, coordinate_clause, subordinate_clause\n","\n","# Example usage\n","text = '''This is an important aspect of today time.\n","This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n","Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n","To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n","More people go to this program television to talk about your problem, that is very radicate in my nation.\n","The modern society rappresented the perfect ambient to influenced the minds of all the person.\n","In my self is present the reasons of this statement, that is one of the problem of the life.\n","But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n","Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n","But to explain all the aspect about this argoment is very inportant to illustre any examples.\n","The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n","This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n","The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n","The my request is that the new politics discuss about this problem.'''\n","\n","\n","def count_sentences(text):\n","    # Split text into sentences based on \"\\n\", \"\\t\", and \".\"\n","    sentences = [sentence.strip() for sentence in text.replace('\\n', '\\t').split('\\t')]\n","    sentences = [sentence.strip() for s in sentences for sentence in s.split('.')]\n","    # Remove empty strings resulting from extra \"\\t\", \"\\n\" or \".\"\n","    sentences = [sentence for sentence in sentences if sentence]\n","    sentence_count = 0\n","    # Count the finite verbs:\n","    for sentence in sentences:\n","        count = 0\n","        # Tokenize the sentence into words\n","        words = word_tokenize(sentence)\n","\n","        # Tag the words with their part-of-speech (POS)\n","        tagged_words = pos_tag(words)\n","\n","        # Initialize counters\n","        finite_verb_count = 0\n","        coordinate_clause = False\n","        subordinate_clause = False\n","\n","        # Check for coordinate or subordinate clauses\n","        for i, (word, pos) in enumerate(tagged_words):\n","            if pos == 'CC' and i > 0 and i < len(tagged_words) - 1:\n","                coordinate_clause = True\n","            elif pos in ['IN', 'DT', 'WDT'] and i > 0 and i < len(tagged_words) - 1:\n","                subordinate_clause = True\n","\n","        # Count the number of finite verbs\n","        for word, pos in tagged_words:\n","            if pos.startswith('V') and pos != 'VBG':\n","                finite_verb_count += 1\n","\n","        if coordinate_clause == False and subordinate_clause == False:\n","            count = finite_verb_count\n","        else:\n","            count = 1\n","\n","        sentence_count += count\n","\n","\n","    return sentence_count\n","print(count_sentences(text))"]},{"cell_type":"code","execution_count":null,"id":"248e60e7","metadata":{"id":"248e60e7","outputId":"88b8b5e7-3a27-48df-bd53-5f526919bdf0"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","The cat sat on the mat.\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Because it was raining.\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","I went to the store.\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Dog not want to play.\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","Total mistakes in the essay: 10\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package dependency_treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package dependency_treebank is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.parse import DependencyGraph\n","\n","# Download the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('dependency_treebank')\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if parser.root is None or parser.root['rel'] != 'root':\n","        print(\"Error: Sentence does not have a proper root\")\n","        mistake_count += 1\n","\n","    # Check for missing constituents and other criteria\n","    for node in parser.nodes.values():\n","        # Check for missing determiners in noun phrases\n","        if node['tag'] == 'NN' and 'DT' not in node['deps']:\n","            print(\"Error: Missing determiner in noun phrase\")\n","            mistake_count += 1\n","\n","        # Check for subordinating conjunctions without main verbs or gerunds\n","        if node['tag'] in ['IN', 'RB'] and 'ccomp' not in node['deps'] and 'xcomp' not in node['deps']:\n","            print(\"Error: Subordinating conjunction used incorrectly\")\n","            mistake_count += 1\n","\n","    return mistake_count\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        print(sentence)\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    # Print total mistakes in the essay\n","    print(\"Total mistakes in the essay:\", total_mistakes)\n","\n","# Example usage\n","essay = \"\"\"\n","The cat sat on the mat.\n","Because it was raining.\n","I went to the store.\n","Dog not want to play.\n","\"\"\"\n","\n","count_mistakes_in_essay(essay)\n"]},{"cell_type":"code","execution_count":null,"id":"7fae0e83","metadata":{"id":"7fae0e83","outputId":"71c394c0-b531-4564-ed6a-828b6e4cd899"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: \n","The cat sat on the mat.\n","Tokens---------------\n","['The', 'cat', 'sat', 'on', 'the', 'mat', '.']\n","POS TAGS---------------\n","[('The', 'DT'), ('cat', 'NN'), ('sat', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n","DEP STR---------------\n","1\tThe\tDT\t0\tDT\t_\t1\t_\t_\t_\n","2\tcat\tNN\t1\tNN\t_\t2\t_\t_\t_\n","3\tsat\tVBD\t2\tVBD\t_\t3\t_\t_\t_\n","4\ton\tIN\t3\tIN\t_\t4\t_\t_\t_\n","5\tthe\tDT\t4\tDT\t_\t5\t_\t_\t_\n","6\tmat\tNN\t5\tNN\t_\t6\t_\t_\t_\n","7\t.\t.\t6\t.\t_\t7\t_\t_\t_\n","PARSER---------------\n","defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x1223349a0>,\n","            {0: {'address': 0,\n","                 'ctag': 'TOP',\n","                 'deps': defaultdict(<class 'list'>, {'root': []}),\n","                 'feats': None,\n","                 'head': None,\n","                 'lemma': None,\n","                 'rel': None,\n","                 'tag': 'TOP',\n","                 'word': None},\n","             1: {'address': 1,\n","                 'ctag': '0',\n","                 'deps': defaultdict(<class 'list'>, {'_': [1]}),\n","                 'feats': '_',\n","                 'head': 1,\n","                 'lemma': 'DT',\n","                 'rel': '_',\n","                 'tag': 'DT',\n","                 'word': 'The'},\n","             2: {'address': 2,\n","                 'ctag': '1',\n","                 'deps': defaultdict(<class 'list'>, {'_': [2]}),\n","                 'feats': '_',\n","                 'head': 2,\n","                 'lemma': 'NN',\n","                 'rel': '_',\n","                 'tag': 'NN',\n","                 'word': 'cat'},\n","             3: {'address': 3,\n","                 'ctag': '2',\n","                 'deps': defaultdict(<class 'list'>, {'_': [3]}),\n","                 'feats': '_',\n","                 'head': 3,\n","                 'lemma': 'VBD',\n","                 'rel': '_',\n","                 'tag': 'VBD',\n","                 'word': 'sat'},\n","             4: {'address': 4,\n","                 'ctag': '3',\n","                 'deps': defaultdict(<class 'list'>, {'_': [4]}),\n","                 'feats': '_',\n","                 'head': 4,\n","                 'lemma': 'IN',\n","                 'rel': '_',\n","                 'tag': 'IN',\n","                 'word': 'on'},\n","             5: {'address': 5,\n","                 'ctag': '4',\n","                 'deps': defaultdict(<class 'list'>, {'_': [5]}),\n","                 'feats': '_',\n","                 'head': 5,\n","                 'lemma': 'DT',\n","                 'rel': '_',\n","                 'tag': 'DT',\n","                 'word': 'the'},\n","             6: {'address': 6,\n","                 'ctag': '5',\n","                 'deps': defaultdict(<class 'list'>, {'_': [6]}),\n","                 'feats': '_',\n","                 'head': 6,\n","                 'lemma': 'NN',\n","                 'rel': '_',\n","                 'tag': 'NN',\n","                 'word': 'mat'},\n","             7: {'address': 7,\n","                 'ctag': '6',\n","                 'deps': defaultdict(<class 'list'>, {'_': [7]}),\n","                 'feats': '_',\n","                 'head': 7,\n","                 'lemma': '.',\n","                 'rel': '_',\n","                 'tag': '.',\n","                 'word': '.'}})\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Sentence: Because it was raining.\n","Tokens---------------\n","['Because', 'it', 'was', 'raining', '.']\n","POS TAGS---------------\n","[('Because', 'IN'), ('it', 'PRP'), ('was', 'VBD'), ('raining', 'VBG'), ('.', '.')]\n","DEP STR---------------\n","1\tBecause\tIN\t0\tIN\t_\t1\t_\t_\t_\n","2\tit\tPRP\t1\tPRP\t_\t2\t_\t_\t_\n","3\twas\tVBD\t2\tVBD\t_\t3\t_\t_\t_\n","4\training\tVBG\t3\tVBG\t_\t4\t_\t_\t_\n","5\t.\t.\t4\t.\t_\t5\t_\t_\t_\n","PARSER---------------\n","defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x1223349a0>,\n","            {0: {'address': 0,\n","                 'ctag': 'TOP',\n","                 'deps': defaultdict(<class 'list'>, {'root': []}),\n","                 'feats': None,\n","                 'head': None,\n","                 'lemma': None,\n","                 'rel': None,\n","                 'tag': 'TOP',\n","                 'word': None},\n","             1: {'address': 1,\n","                 'ctag': '0',\n","                 'deps': defaultdict(<class 'list'>, {'_': [1]}),\n","                 'feats': '_',\n","                 'head': 1,\n","                 'lemma': 'IN',\n","                 'rel': '_',\n","                 'tag': 'IN',\n","                 'word': 'Because'},\n","             2: {'address': 2,\n","                 'ctag': '1',\n","                 'deps': defaultdict(<class 'list'>, {'_': [2]}),\n","                 'feats': '_',\n","                 'head': 2,\n","                 'lemma': 'PRP',\n","                 'rel': '_',\n","                 'tag': 'PRP',\n","                 'word': 'it'},\n","             3: {'address': 3,\n","                 'ctag': '2',\n","                 'deps': defaultdict(<class 'list'>, {'_': [3]}),\n","                 'feats': '_',\n","                 'head': 3,\n","                 'lemma': 'VBD',\n","                 'rel': '_',\n","                 'tag': 'VBD',\n","                 'word': 'was'},\n","             4: {'address': 4,\n","                 'ctag': '3',\n","                 'deps': defaultdict(<class 'list'>, {'_': [4]}),\n","                 'feats': '_',\n","                 'head': 4,\n","                 'lemma': 'VBG',\n","                 'rel': '_',\n","                 'tag': 'VBG',\n","                 'word': 'raining'},\n","             5: {'address': 5,\n","                 'ctag': '4',\n","                 'deps': defaultdict(<class 'list'>, {'_': [5]}),\n","                 'feats': '_',\n","                 'head': 5,\n","                 'lemma': '.',\n","                 'rel': '_',\n","                 'tag': '.',\n","                 'word': '.'}})\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","Sentence: I went to the store.\n","Tokens---------------\n","['I', 'went', 'to', 'the', 'store', '.']\n","POS TAGS---------------\n","[('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('store', 'NN'), ('.', '.')]\n","DEP STR---------------\n","1\tI\tPRP\t0\tPRP\t_\t1\t_\t_\t_\n","2\twent\tVBD\t1\tVBD\t_\t2\t_\t_\t_\n","3\tto\tTO\t2\tTO\t_\t3\t_\t_\t_\n","4\tthe\tDT\t3\tDT\t_\t4\t_\t_\t_\n","5\tstore\tNN\t4\tNN\t_\t5\t_\t_\t_\n","6\t.\t.\t5\t.\t_\t6\t_\t_\t_\n","PARSER---------------\n","defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x1223349a0>,\n","            {0: {'address': 0,\n","                 'ctag': 'TOP',\n","                 'deps': defaultdict(<class 'list'>, {'root': []}),\n","                 'feats': None,\n","                 'head': None,\n","                 'lemma': None,\n","                 'rel': None,\n","                 'tag': 'TOP',\n","                 'word': None},\n","             1: {'address': 1,\n","                 'ctag': '0',\n","                 'deps': defaultdict(<class 'list'>, {'_': [1]}),\n","                 'feats': '_',\n","                 'head': 1,\n","                 'lemma': 'PRP',\n","                 'rel': '_',\n","                 'tag': 'PRP',\n","                 'word': 'I'},\n","             2: {'address': 2,\n","                 'ctag': '1',\n","                 'deps': defaultdict(<class 'list'>, {'_': [2]}),\n","                 'feats': '_',\n","                 'head': 2,\n","                 'lemma': 'VBD',\n","                 'rel': '_',\n","                 'tag': 'VBD',\n","                 'word': 'went'},\n","             3: {'address': 3,\n","                 'ctag': '2',\n","                 'deps': defaultdict(<class 'list'>, {'_': [3]}),\n","                 'feats': '_',\n","                 'head': 3,\n","                 'lemma': 'TO',\n","                 'rel': '_',\n","                 'tag': 'TO',\n","                 'word': 'to'},\n","             4: {'address': 4,\n","                 'ctag': '3',\n","                 'deps': defaultdict(<class 'list'>, {'_': [4]}),\n","                 'feats': '_',\n","                 'head': 4,\n","                 'lemma': 'DT',\n","                 'rel': '_',\n","                 'tag': 'DT',\n","                 'word': 'the'},\n","             5: {'address': 5,\n","                 'ctag': '4',\n","                 'deps': defaultdict(<class 'list'>, {'_': [5]}),\n","                 'feats': '_',\n","                 'head': 5,\n","                 'lemma': 'NN',\n","                 'rel': '_',\n","                 'tag': 'NN',\n","                 'word': 'store'},\n","             6: {'address': 6,\n","                 'ctag': '5',\n","                 'deps': defaultdict(<class 'list'>, {'_': [6]}),\n","                 'feats': '_',\n","                 'head': 6,\n","                 'lemma': '.',\n","                 'rel': '_',\n","                 'tag': '.',\n","                 'word': '.'}})\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Sentence: Dog not want to play.\n","Tokens---------------\n","['Dog', 'not', 'want', 'to', 'play', '.']\n","POS TAGS---------------\n","[('Dog', 'NNP'), ('not', 'RB'), ('want', 'VB'), ('to', 'TO'), ('play', 'VB'), ('.', '.')]\n","DEP STR---------------\n","1\tDog\tNNP\t0\tNNP\t_\t1\t_\t_\t_\n","2\tnot\tRB\t1\tRB\t_\t2\t_\t_\t_\n","3\twant\tVB\t2\tVB\t_\t3\t_\t_\t_\n","4\tto\tTO\t3\tTO\t_\t4\t_\t_\t_\n","5\tplay\tVB\t4\tVB\t_\t5\t_\t_\t_\n","6\t.\t.\t5\t.\t_\t6\t_\t_\t_\n","PARSER---------------\n","defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x1223349a0>,\n","            {0: {'address': 0,\n","                 'ctag': 'TOP',\n","                 'deps': defaultdict(<class 'list'>, {'root': []}),\n","                 'feats': None,\n","                 'head': None,\n","                 'lemma': None,\n","                 'rel': None,\n","                 'tag': 'TOP',\n","                 'word': None},\n","             1: {'address': 1,\n","                 'ctag': '0',\n","                 'deps': defaultdict(<class 'list'>, {'_': [1]}),\n","                 'feats': '_',\n","                 'head': 1,\n","                 'lemma': 'NNP',\n","                 'rel': '_',\n","                 'tag': 'NNP',\n","                 'word': 'Dog'},\n","             2: {'address': 2,\n","                 'ctag': '1',\n","                 'deps': defaultdict(<class 'list'>, {'_': [2]}),\n","                 'feats': '_',\n","                 'head': 2,\n","                 'lemma': 'RB',\n","                 'rel': '_',\n","                 'tag': 'RB',\n","                 'word': 'not'},\n","             3: {'address': 3,\n","                 'ctag': '2',\n","                 'deps': defaultdict(<class 'list'>, {'_': [3]}),\n","                 'feats': '_',\n","                 'head': 3,\n","                 'lemma': 'VB',\n","                 'rel': '_',\n","                 'tag': 'VB',\n","                 'word': 'want'},\n","             4: {'address': 4,\n","                 'ctag': '3',\n","                 'deps': defaultdict(<class 'list'>, {'_': [4]}),\n","                 'feats': '_',\n","                 'head': 4,\n","                 'lemma': 'TO',\n","                 'rel': '_',\n","                 'tag': 'TO',\n","                 'word': 'to'},\n","             5: {'address': 5,\n","                 'ctag': '4',\n","                 'deps': defaultdict(<class 'list'>, {'_': [5]}),\n","                 'feats': '_',\n","                 'head': 5,\n","                 'lemma': 'VB',\n","                 'rel': '_',\n","                 'tag': 'VB',\n","                 'word': 'play'},\n","             6: {'address': 6,\n","                 'ctag': '5',\n","                 'deps': defaultdict(<class 'list'>, {'_': [6]}),\n","                 'feats': '_',\n","                 'head': 6,\n","                 'lemma': '.',\n","                 'rel': '_',\n","                 'tag': '.',\n","                 'word': '.'}})\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","Total mistakes in the essay: 10\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package dependency_treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package dependency_treebank is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.parse import DependencyGraph\n","\n","# Download the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('dependency_treebank')\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    print(\"Sentence:\", sentence)\n","\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","    print('Tokens---------------')\n","    print(tokens)\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","    print('POS TAGS---------------')\n","    print(pos_tags)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","    print('DEP STR---------------')\n","    print(dep_str)\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","    print('PARSER---------------')\n","    print(parser)\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if parser.root is None or parser.root['rel'] != 'root':\n","        print(\"Error: Sentence does not have a proper root\")\n","        mistake_count += 1\n","\n","    # Check for missing constituents and other criteria\n","    for node in parser.nodes.values():\n","        # Check for missing determiners in noun phrases\n","        if node['tag'] == 'NN' and 'DT' not in node['deps']:\n","            print(\"Error: Missing determiner in noun phrase\")\n","            mistake_count += 1\n","\n","        # Check for subordinating conjunctions without main verbs or gerunds\n","        if node['tag'] in ['IN', 'RB'] and 'ccomp' not in node['deps'] and 'xcomp' not in node['deps']:\n","            print(\"Error: Subordinating conjunction used incorrectly\")\n","            mistake_count += 1\n","\n","    return mistake_count\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    # Print total mistakes in the essay\n","    print(\"Total mistakes in the essay:\", total_mistakes)\n","\n","# Example usage\n","essay = \"\"\"\n","The cat sat on the mat.\n","Because it was raining.\n","I went to the store.\n","Dog not want to play.\n","\"\"\"\n","\n","count_mistakes_in_essay(essay)\n"]},{"cell_type":"code","execution_count":null,"id":"9ab00c51","metadata":{"id":"9ab00c51","outputId":"7290376b-0fe8-4e6d-b45a-9b059526969f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Total mistakes in the essay: 134\n","None\n"]}],"source":["\n","\n","essay = '''This is an important aspect of today time.\n","This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n","Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n","To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n","More people go to this program television to talk about your problem, that is very radicate in my nation.\n","The modern society rappresented the perfect ambient to influenced the minds of all the person.\n","In my self is present the reasons of this statement, that is one of the problem of the life.\n","But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n","Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n","But to explain all the aspect about this argoment is very inportant to illustre any examples.\n","The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n","This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n","The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n","The my request is that the new politics discuss about this problem.'''\n","\n","print(count_mistakes_in_essay(essay))"]},{"cell_type":"code","execution_count":null,"id":"33f8578f","metadata":{"id":"33f8578f"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e3860ec0","metadata":{"id":"e3860ec0","outputId":"fac57b88-01f0-49e1-9fb9-bc4de3c9ac2d"},"outputs":[{"name":"stderr","output_type":"stream","text":["python(69460) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in /Users/shwetaparihar/anaconda3/lib/python3.11/site-packages (3.8.1)\r\n","Requirement already satisfied: click in /Users/shwetaparihar/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\r\n","Requirement already satisfied: joblib in /Users/shwetaparihar/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\r\n","Requirement already satisfied: regex>=2021.8.3 in /Users/shwetaparihar/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\r\n","Requirement already satisfied: tqdm in /Users/shwetaparihar/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\r\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data] Downloading package words to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n","[nltk_data] Downloading package treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n"]},{"name":"stdout","output_type":"stream","text":["Error parsing sentence: My dog with a broken leg I not want. ChartParser.__init__() missing 1 required positional argument: 'grammar'\n","Error parsing sentence: I do not want my dog with a broken leg. ChartParser.__init__() missing 1 required positional argument: 'grammar'\n","Error parsing sentence: I came because he was sick. ChartParser.__init__() missing 1 required positional argument: 'grammar'\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data]   Unzipping corpora/treebank.zip.\n"]}],"source":["!pip install nltk\n","\n","import nltk\n","from nltk import Tree\n","\n","# Sample sentences\n","sentences = [\n","    \"My dog with a broken leg I not want.\",\n","    \"I do not want my dog with a broken leg.\",\n","    \"I came because he was sick.\"\n","]\n","\n","# Constituency parsing function\n","def constituency_parse(sentence):\n","    return nltk.ChartParser().parse(sentence.split())\n","\n","# Check well-formedness of sentences\n","def check_wellformedness(sentences):\n","    for sentence in sentences:\n","        try:\n","            # Parse the sentence\n","            parse_tree = next(constituency_parse(sentence))\n","            # Check for common mistakes in parse tree\n","            # Add your checks here based on identified patterns\n","            # For example:\n","            if 'SBAR' in str(parse_tree):\n","                print(\"Subordinate clause found:\", sentence)\n","            else:\n","                print(\"Sentence is well-formed:\", sentence)\n","        except Exception as e:\n","            print(\"Error parsing sentence:\", sentence, e)\n","\n","# Check well-formedness of sentences\n","check_wellformedness(sentences)\n"]},{"cell_type":"code","execution_count":null,"id":"f1eb8079","metadata":{"id":"f1eb8079"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"2dd687e0","metadata":{"id":"2dd687e0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9cc7f898","metadata":{"id":"9cc7f898"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"33274c4c","metadata":{"id":"33274c4c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"cb5d17ec","metadata":{"id":"cb5d17ec"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"54c57335","metadata":{"id":"54c57335","outputId":"f47caef1-ba89-4bbc-bb7e-779518023b42"},"outputs":[{"name":"stderr","output_type":"stream","text":["python(70194) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in /Users/shwetaparihar/anaconda3/lib/python3.11/site-packages (3.8.1)\n","Requirement already satisfied: click in /Users/shwetaparihar/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n","Requirement already satisfied: joblib in /Users/shwetaparihar/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /Users/shwetaparihar/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n","Requirement already satisfied: tqdm in /Users/shwetaparihar/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n","(The (cat (sat (on (the (mat .))))))\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n","[nltk_data] Downloading package treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package treebank is already up-to-date!\n","[nltk_data] Downloading package universal_tagset to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package universal_tagset is already up-to-date!\n"]}],"source":["!pip install nltk\n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","nltk.download('treebank')\n","nltk.download('universal_tagset')\n","\n","import nltk\n","from nltk.parse import DependencyGraph\n","\n","sentence = 'The cat sat on the mat.'\n","\n","# Tokenize the sentence\n","tokens = nltk.word_tokenize(sentence)\n","\n","# Part-of-speech tagging\n","pos_tags = nltk.pos_tag(tokens)\n","\n","# Convert POS tags to Universal Dependency tags\n","pos_tags = [(word, nltk.map_tag('en-ptb', 'universal', tag)) for word, tag in pos_tags]\n","\n","# Create a string in CoNLL format\n","conll_format = '\\n'.join(['\\t'.join((str(i+1), word, '_', pos, pos, '_',\n","                                    str(head), rel if rel else 'ROOT', '_', '_'))\n","                                    for i, ((word, pos), (head, rel)) in enumerate(zip(pos_tags, [(0, None)] + [(i+1, 'root') for i in range(len(tokens))]))])\n","\n","# Parse the CoNLL format string into a DependencyGraph\n","graph = DependencyGraph(conll_format)\n","\n","# Print the dependencies\n","print(graph.tree())\n"]},{"cell_type":"code","execution_count":null,"id":"01adde63","metadata":{"id":"01adde63","outputId":"fd80077f-4471-40b5-eb66-ac043f93e974"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: \n","The cat sat on the mat.\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Sentence: Because it was raining.\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","Sentence: I went to the store.\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Sentence: Dog not want to play.\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","Total mistakes in the essay: 10\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package dependency_treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package dependency_treebank is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.parse import DependencyGraph\n","\n","# Download the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('dependency_treebank')\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    print(\"Sentence:\", sentence)\n","\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if parser.root is None or parser.root['rel'] != 'root':\n","        print(\"Error: Sentence does not have a proper root\")\n","        mistake_count += 1\n","\n","    # Check for missing constituents and other criteria\n","    for node in parser.nodes.values():\n","        # Check for missing determiners in noun phrases\n","        if node['tag'] == 'NN' and 'DT' not in node['deps']:\n","            print(\"Error: Missing determiner in noun phrase\")\n","            mistake_count += 1\n","\n","        # Check for subordinating conjunctions without main verbs or gerunds\n","        if node['tag'] in ['IN', 'RB'] and 'ccomp' not in node['deps'] and 'xcomp' not in node['deps']:\n","            print(\"Error: Subordinating conjunction used incorrectly\")\n","            mistake_count += 1\n","\n","    return mistake_count\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    # Print total mistakes in the essay\n","    print(\"Total mistakes in the essay:\", total_mistakes)\n","\n","# Example usage\n","essay = \"\"\"\n","The cat sat on the mat.\n","Because it was raining.\n","I went to the store.\n","Dog not want to play.\n","\"\"\"\n","\n","count_mistakes_in_essay(essay)\n"]},{"cell_type":"code","execution_count":null,"id":"1302db22","metadata":{"id":"1302db22","outputId":"3bde7c67-7868-4857-a757-387db9fee812"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: \n","The cat sat on the mat.\n","Tokens: ['The', 'cat', 'sat', 'on', 'the', 'mat', '.']\n","POS Tags: [('The', 'DT'), ('cat', 'NN'), ('sat', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Error: Subordinating conjunction used incorrectly\n","Error: Missing determiner in noun phrase\n","Sentence: Because it was raining.\n","Tokens: ['Because', 'it', 'was', 'raining', '.']\n","POS Tags: [('Because', 'IN'), ('it', 'PRP'), ('was', 'VBD'), ('raining', 'VBG'), ('.', '.')]\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","Sentence: I went to the store.\n","Tokens: ['I', 'went', 'to', 'the', 'store', '.']\n","POS Tags: [('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('store', 'NN'), ('.', '.')]\n","Error: Sentence does not have a proper root\n","Error: Missing determiner in noun phrase\n","Sentence: Dog not want to play.\n","Tokens: ['Dog', 'not', 'want', 'to', 'play', '.']\n","POS Tags: [('Dog', 'NNP'), ('not', 'RB'), ('want', 'VB'), ('to', 'TO'), ('play', 'VB'), ('.', '.')]\n","Error: Sentence does not have a proper root\n","Error: Subordinating conjunction used incorrectly\n","Total mistakes in the essay: 10\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package dependency_treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package dependency_treebank is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.parse import DependencyGraph\n","\n","# Download the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('dependency_treebank')\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    print(\"Sentence:\", sentence)\n","\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","    print(\"Tokens:\", tokens)\n","\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","    print(\"POS Tags:\", pos_tags)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if parser.root is None or parser.root['rel'] != 'root':\n","        print(\"Error: Sentence does not have a proper root\")\n","        mistake_count += 1\n","\n","    # Check for missing constituents and other criteria\n","    for node in parser.nodes.values():\n","        # Check for missing determiners in noun phrases\n","        if node['tag'] == 'NN' and 'DT' not in node['deps']:\n","            print(\"Error: Missing determiner in noun phrase\")\n","            mistake_count += 1\n","\n","        # Check for subordinating conjunctions without main verbs or gerunds\n","        if node['tag'] in ['IN', 'RB'] and 'ccomp' not in node['deps'] and 'xcomp' not in node['deps']:\n","            print(\"Error: Subordinating conjunction used incorrectly\")\n","            mistake_count += 1\n","\n","    return mistake_count\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    # Print total mistakes in the essay\n","    print(\"Total mistakes in the essay:\", total_mistakes)\n","\n","# Example usage\n","essay = \"\"\"\n","The cat sat on the mat.\n","Because it was raining.\n","I went to the store.\n","Dog not want to play.\n","\"\"\"\n","\n","count_mistakes_in_essay(essay)\n"]},{"cell_type":"code","execution_count":null,"id":"44c9cb8f","metadata":{"id":"44c9cb8f"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fb86f13b","metadata":{"id":"fb86f13b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"afca5687","metadata":{"id":"afca5687"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"442ef914","metadata":{"id":"442ef914"},"outputs":[],"source":["##################### FINAL #######################"]},{"cell_type":"code","execution_count":null,"id":"f4591a66","metadata":{"id":"f4591a66","outputId":"768bfa28-a659-45da-bef5-bbf13e1b7a69"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: \n","The cat sat on the mat.\n","Tokens: ['The', 'cat', 'sat', 'on', 'the', 'mat', '.']\n","POS Tags: [('The', 'DT'), ('cat', 'NN'), ('sat', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n","Sentence: Because it was raining.\n","Tokens: ['Because', 'it', 'was', 'raining', '.']\n","POS Tags: [('Because', 'IN'), ('it', 'PRP'), ('was', 'VBD'), ('raining', 'VBG'), ('.', '.')]\n","Error: Subordinating conjunction is used incorrectly\n","Sentence: I went to the store.\n","Tokens: ['I', 'went', 'to', 'the', 'store', '.']\n","POS Tags: [('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('store', 'NN'), ('.', '.')]\n","Sentence: Dog not want to play.\n","Tokens: ['Dog', 'not', 'want', 'to', 'play', '.']\n","POS Tags: [('Dog', 'NNP'), ('not', 'RB'), ('want', 'VB'), ('to', 'TO'), ('play', 'VB'), ('.', '.')]\n","Error: Main sentence formation is not proper\n","Total mistakes in the essay: 2\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package dependency_treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package dependency_treebank is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.parse import DependencyGraph\n","\n","# Download the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('dependency_treebank')\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    print(\"Sentence:\", sentence)\n","\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","    print(\"Tokens:\", tokens)\n","\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","    print(\"POS Tags:\", pos_tags)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if not is_main_sentence_formed_properly(pos_tags):\n","        print(\"Error: Main sentence formation is not proper\")\n","        mistake_count += 1\n","\n","    # Check for missing constituents\n","    if not are_constituents_formed_properly(pos_tags):\n","        print(\"Error: Constituents are not formed properly\")\n","        mistake_count += 1\n","\n","    # Check for subordinating conjunctions\n","    if not is_subordinating_conjunction_correct(pos_tags):\n","        print(\"Error: Subordinating conjunction is used incorrectly\")\n","        mistake_count += 1\n","\n","    return mistake_count\n","\n","# Function to check if main sentence formation is proper\n","def is_main_sentence_formed_properly(pos_tags):\n","    # Check if the sentence starts with a valid word\n","    first_word_tag = pos_tags[0][1]\n","    if first_word_tag in ['VB', 'VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Verbs\n","        return False\n","\n","    # Check for negation adverb before the main verb\n","    for i in range(1, len(pos_tags)):\n","        if pos_tags[i][1] == 'VB' and pos_tags[i-1][1] == 'RB' and pos_tags[i-1][0].lower() == 'not':\n","            return False\n","\n","    return True\n","\n","# Function to check if constituents are formed properly\n","def are_constituents_formed_properly(pos_tags):\n","    # Check for missing determiners in noun phrases\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'NN' and (i == 0 or pos_tags[i-1][1] != 'DT'):\n","            return False\n","    return True\n","\n","# Function to check if subordinating conjunction is used correctly\n","def is_subordinating_conjunction_correct(pos_tags):\n","    subordinating_conjunctions = ['when', 'although', 'if', 'because']\n","    for word, tag in pos_tags:\n","        if word.lower() in subordinating_conjunctions:\n","            # Check if the corresponding clause is finite or includes a gerund\n","            if tag not in ['VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Finite verbs or gerunds\n","                return False\n","    return True\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    # Print total mistakes in the essay\n","    print(\"Total mistakes in the essay:\", total_mistakes)\n","\n","# Example usage\n","essay = \"\"\"\n","The cat sat on the mat.\n","Because it was raining.\n","I went to the store.\n","Dog not want to play.\n","\"\"\"\n","\n","count_mistakes_in_essay(essay)\n"]},{"cell_type":"code","execution_count":null,"id":"9286460e","metadata":{"id":"9286460e","outputId":"b014a27e-3553-45a8-893e-7531fd35a68f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: \n","The cat sat on the mat.\n","Tokens: ['The', 'cat', 'sat', 'on', 'the', 'mat', '.']\n","POS Tags: [('The', 'DT'), ('cat', 'NN'), ('sat', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n","Sentence: Because it was raining.\n","Tokens: ['Because', 'it', 'was', 'raining', '.']\n","POS Tags: [('Because', 'IN'), ('it', 'PRP'), ('was', 'VBD'), ('raining', 'VBG'), ('.', '.')]\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","Sentence: I went to the store.\n","Tokens: ['I', 'went', 'to', 'the', 'store', '.']\n","POS Tags: [('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('store', 'NN'), ('.', '.')]\n","Error: Verb agreement and tense consistency issue\n","Sentence: Dog not want to play.\n","Tokens: ['Dog', 'not', 'want', 'to', 'play', '.']\n","POS Tags: [('Dog', 'NNP'), ('not', 'RB'), ('want', 'VB'), ('to', 'TO'), ('play', 'VB'), ('.', '.')]\n","Error: Main sentence formation is not proper\n","Total mistakes in the essay: 4\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package dependency_treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package dependency_treebank is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.parse import DependencyGraph\n","\n","# Download the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('dependency_treebank')\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    print(\"Sentence:\", sentence)\n","\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","    print(\"Tokens:\", tokens)\n","\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","    print(\"POS Tags:\", pos_tags)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if not is_main_sentence_formed_properly(pos_tags):\n","        print(\"Error: Main sentence formation is not proper\")\n","        mistake_count += 1\n","\n","    # Check for missing constituents\n","    if not are_constituents_formed_properly(pos_tags):\n","        print(\"Error: Constituents are not formed properly\")\n","        mistake_count += 1\n","\n","    # Check for subordinating conjunctions\n","    if not is_subordinating_conjunction_correct(pos_tags):\n","        print(\"Error: Subordinating conjunction is used incorrectly\")\n","        mistake_count += 1\n","\n","    # Check for verb agreement and tense consistency\n","    if not is_verb_agreement_and_tense_consistent(pos_tags):\n","        print(\"Error: Verb agreement and tense consistency issue\")\n","        mistake_count += 1\n","\n","    # Check for conjunction usage\n","    if not is_conjunction_usage_correct(pos_tags):\n","        print(\"Error: Conjunction usage is incorrect\")\n","        mistake_count += 1\n","\n","    return mistake_count\n","\n","# Function to check if main sentence formation is proper\n","def is_main_sentence_formed_properly(pos_tags):\n","    # Check if the sentence starts with a valid word\n","    first_word_tag = pos_tags[0][1]\n","    if first_word_tag in ['VB', 'VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Verbs\n","        return False\n","\n","    # Check for negation adverb before the main verb\n","    for i in range(1, len(pos_tags)):\n","        if pos_tags[i][1] == 'VB' and pos_tags[i-1][1] == 'RB' and pos_tags[i-1][0].lower() == 'not':\n","            return False\n","\n","    return True\n","\n","# Function to check if constituents are formed properly\n","def are_constituents_formed_properly(pos_tags):\n","    # Check for missing determiners in noun phrases\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'NN' and (i == 0 or pos_tags[i-1][1] != 'DT'):\n","            return False\n","    return True\n","\n","# Function to check if subordinating conjunction is used correctly\n","def is_subordinating_conjunction_correct(pos_tags):\n","    subordinating_conjunctions = ['when', 'although', 'if', 'because']\n","    for word, tag in pos_tags:\n","        if word.lower() in subordinating_conjunctions:\n","            # Check if the corresponding clause is finite or includes a gerund\n","            if tag not in ['VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Finite verbs or gerunds\n","                return False\n","    return True\n","\n","# Function to check if verb agreement and tense consistency are correct\n","def is_verb_agreement_and_tense_consistent(pos_tags):\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] in ['VBZ', 'VBG', 'VBD', 'VBN']:  # Verbs in non-base form\n","            if i == 0 or pos_tags[i-1][1] != 'NN':  # Verb is not preceded by a noun\n","                return False\n","    return True\n","\n","# Function to check if conjunction usage is correct\n","def is_conjunction_usage_correct(pos_tags):\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'CC':  # Conjunction\n","            if i == 0 or i == len(pos_tags) - 1:  # Conjunction appears at the beginning or end of the sentence\n","                return False\n","    return True\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    # Print total mistakes in the essay\n","    print(\"Total mistakes in the essay:\", total_mistakes)\n","\n","# Example usage\n","essay = \"\"\"\n","The cat sat on the mat.\n","Because it was raining.\n","I went to the store.\n","Dog not want to play.\n","\"\"\"\n","\n","count_mistakes_in_essay(essay)\n"]},{"cell_type":"code","execution_count":null,"id":"087aa2df","metadata":{"id":"087aa2df","outputId":"49a1a504-b747-4225-f1fc-fddc2fad8718"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: \n","The cat sat on the mat.\n","Tokens: ['The', 'cat', 'sat', 'on', 'the', 'mat', '.']\n","POS Tags: [('The', 'DT'), ('cat', 'NN'), ('sat', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n","Error: Verb agreement and tense consistency issue\n","Sentence: Because it was raining.\n","Tokens: ['Because', 'it', 'was', 'raining', '.']\n","POS Tags: [('Because', 'IN'), ('it', 'PRP'), ('was', 'VBD'), ('raining', 'VBG'), ('.', '.')]\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","Sentence: I went to the store.\n","Tokens: ['I', 'went', 'to', 'the', 'store', '.']\n","POS Tags: [('I', 'PRP'), ('went', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('store', 'NN'), ('.', '.')]\n","Sentence: Dog not want to play.\n","Tokens: ['Dog', 'not', 'want', 'to', 'play', '.']\n","POS Tags: [('Dog', 'NNP'), ('not', 'RB'), ('want', 'VB'), ('to', 'TO'), ('play', 'VB'), ('.', '.')]\n","Error: Main sentence formation is not proper\n","Total mistakes in the essay: 4\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package dependency_treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package dependency_treebank is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.parse import DependencyGraph\n","\n","# Download the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('dependency_treebank')\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    print(\"Sentence:\", sentence)\n","\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","    print(\"Tokens:\", tokens)\n","\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","    print(\"POS Tags:\", pos_tags)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if not is_main_sentence_formed_properly(pos_tags):\n","        print(\"Error: Main sentence formation is not proper\")\n","        mistake_count += 1\n","\n","    # Check for missing constituents\n","    if not are_constituents_formed_properly(pos_tags):\n","        print(\"Error: Constituents are not formed properly\")\n","        mistake_count += 1\n","\n","    # Check for subordinating conjunctions\n","    if not is_subordinating_conjunction_correct(pos_tags):\n","        print(\"Error: Subordinating conjunction is used incorrectly\")\n","        mistake_count += 1\n","\n","    # Check for verb agreement and tense consistency\n","    if not is_verb_agreement_and_tense_consistent(pos_tags):\n","        print(\"Error: Verb agreement and tense consistency issue\")\n","        mistake_count += 1\n","\n","    # Check for conjunction usage\n","    if not is_conjunction_usage_correct(pos_tags):\n","        print(\"Error: Conjunction usage is incorrect\")\n","        mistake_count += 1\n","\n","    return mistake_count\n","\n","# Function to check if main sentence formation is proper\n","def is_main_sentence_formed_properly(pos_tags):\n","    # Check if the sentence starts with a valid word\n","    first_word_tag = pos_tags[0][1]\n","    if first_word_tag in ['VB', 'VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Verbs\n","        return False\n","\n","    # Check for negation adverb before the main verb\n","    for i in range(1, len(pos_tags)):\n","        if pos_tags[i][1] == 'VB' and pos_tags[i-1][1] == 'RB' and pos_tags[i-1][0].lower() == 'not':\n","            return False\n","\n","    return True\n","\n","# Function to check if constituents are formed properly\n","def are_constituents_formed_properly(pos_tags):\n","    # Check for missing determiners in noun phrases\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'NN' and (i == 0 or pos_tags[i-1][1] != 'DT'):\n","            return False\n","    return True\n","\n","# Function to check if subordinating conjunction is used correctly\n","def is_subordinating_conjunction_correct(pos_tags):\n","    subordinating_conjunctions = ['when', 'although', 'if', 'because']\n","    for word, tag in pos_tags:\n","        if word.lower() in subordinating_conjunctions:\n","            # Check if the corresponding clause is finite or includes a gerund\n","            if tag not in ['VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Finite verbs or gerunds\n","                return False\n","    return True\n","\n","# Function to check if verb agreement and tense consistency are correct\n","def is_verb_agreement_and_tense_consistent(pos_tags):\n","    for i in range(len(pos_tags)):\n","        word, tag = pos_tags[i]\n","        if tag in ['VBZ', 'VBG', 'VBD', 'VBN']:  # Verbs in non-base form\n","            if i == 0 or pos_tags[i-1][1] != 'PRP':  # Verb is not preceded by a personal pronoun\n","                return False\n","    return True\n","\n","\n","# Function to check if conjunction usage is correct\n","def is_conjunction_usage_correct(pos_tags):\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'CC':  # Conjunction\n","            if i == 0 or i == len(pos_tags) - 1:  # Conjunction appears at the beginning or end of the sentence\n","                return False\n","    return True\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    # Print total mistakes in the essay\n","    print(\"Total mistakes in the essay:\", total_mistakes)\n","\n","# Example usage\n","essay = \"\"\"\n","The cat sat on the mat.\n","Because it was raining.\n","I went to the store.\n","Dog not want to play.\n","\"\"\"\n","\n","count_mistakes_in_essay(essay)\n"]},{"cell_type":"code","execution_count":null,"id":"a88bc632","metadata":{"id":"a88bc632","outputId":"31d43d12-06de-414e-b3b2-3ef4bab394a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["=================================================\n","Sentence: 'This is an important aspect of today time.\n","Tokens: [\"'This\", 'is', 'an', 'important', 'aspect', 'of', 'today', 'time', '.']\n","POS Tags: [(\"'This\", 'NN'), ('is', 'VBZ'), ('an', 'DT'), ('important', 'JJ'), ('aspect', 'NN'), ('of', 'IN'), ('today', 'NN'), ('time', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","=================================================\n","Sentence: This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n","Tokens: ['This', 'products', 'rathen', 'are', 'not', 'much', 'better', ',', 'but', 'today', 'is', 'not', 'important', 'the', 'really', 'character', 'of', 'the', 'product', ',', 'but', 'only', 'the', 'money', 'and', 'the', 'client', 'not', 'rappresented', 'the', 'important', 'actor', 'in', 'this', 'process', '.']\n","POS Tags: [('This', 'DT'), ('products', 'NNS'), ('rathen', 'NN'), ('are', 'VBP'), ('not', 'RB'), ('much', 'JJ'), ('better', 'RBR'), (',', ','), ('but', 'CC'), ('today', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('important', 'JJ'), ('the', 'DT'), ('really', 'RB'), ('character', 'NN'), ('of', 'IN'), ('the', 'DT'), ('product', 'NN'), (',', ','), ('but', 'CC'), ('only', 'RB'), ('the', 'DT'), ('money', 'NN'), ('and', 'CC'), ('the', 'DT'), ('client', 'NN'), ('not', 'RB'), ('rappresented', 'VBD'), ('the', 'DT'), ('important', 'JJ'), ('actor', 'NN'), ('in', 'IN'), ('this', 'DT'), ('process', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n","Tokens: ['Every', 'day', 'any', 'people', 'buy', 'same', 'products', 'that', 'is', 'not', 'rappresented', 'the', 'your', 'necessity', ',', 'but', 'is', 'only', 'important', 'buy', 'any', 'product', '.']\n","POS Tags: [('Every', 'DT'), ('day', 'NN'), ('any', 'DT'), ('people', 'NNS'), ('buy', 'VBP'), ('same', 'JJ'), ('products', 'NNS'), ('that', 'WDT'), ('is', 'VBZ'), ('not', 'RB'), ('rappresented', 'VBN'), ('the', 'DT'), ('your', 'PRP$'), ('necessity', 'NN'), (',', ','), ('but', 'CC'), ('is', 'VBZ'), ('only', 'RB'), ('important', 'JJ'), ('buy', 'VB'), ('any', 'DT'), ('product', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n","Tokens: ['To', 'explain', 'this', 'argoment', 'in', 'my', 'nation', ',', 'at', 'the', 'television', ',', 'there', 'is', 'an', 'program', 'that', 'discuss', 'of', 'the', 'problem', 'rappresented', 'by', 'this', '.']\n","POS Tags: [('To', 'TO'), ('explain', 'VB'), ('this', 'DT'), ('argoment', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('nation', 'NN'), (',', ','), ('at', 'IN'), ('the', 'DT'), ('television', 'NN'), (',', ','), ('there', 'EX'), ('is', 'VBZ'), ('an', 'DT'), ('program', 'NN'), ('that', 'WDT'), ('discuss', 'NN'), ('of', 'IN'), ('the', 'DT'), ('problem', 'NN'), ('rappresented', 'VBN'), ('by', 'IN'), ('this', 'DT'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: More people go to this program television to talk about your problem, that is very radicate in my nation.\n","Tokens: ['More', 'people', 'go', 'to', 'this', 'program', 'television', 'to', 'talk', 'about', 'your', 'problem', ',', 'that', 'is', 'very', 'radicate', 'in', 'my', 'nation', '.']\n","POS Tags: [('More', 'JJR'), ('people', 'NNS'), ('go', 'VBP'), ('to', 'TO'), ('this', 'DT'), ('program', 'NN'), ('television', 'NN'), ('to', 'TO'), ('talk', 'VB'), ('about', 'IN'), ('your', 'PRP$'), ('problem', 'NN'), (',', ','), ('that', 'WDT'), ('is', 'VBZ'), ('very', 'RB'), ('radicate', 'JJ'), ('in', 'IN'), ('my', 'PRP$'), ('nation', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: The modern society rappresented the perfect ambient to influenced the minds of all the person.\n","Tokens: ['The', 'modern', 'society', 'rappresented', 'the', 'perfect', 'ambient', 'to', 'influenced', 'the', 'minds', 'of', 'all', 'the', 'person', '.']\n","POS Tags: [('The', 'DT'), ('modern', 'JJ'), ('society', 'NN'), ('rappresented', 'VBD'), ('the', 'DT'), ('perfect', 'JJ'), ('ambient', 'NN'), ('to', 'TO'), ('influenced', 'VB'), ('the', 'DT'), ('minds', 'NNS'), ('of', 'IN'), ('all', 'PDT'), ('the', 'DT'), ('person', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","=================================================\n","Sentence: In my self is present the reasons of this statement, that is one of the problem of the life.\n","Tokens: ['In', 'my', 'self', 'is', 'present', 'the', 'reasons', 'of', 'this', 'statement', ',', 'that', 'is', 'one', 'of', 'the', 'problem', 'of', 'the', 'life', '.']\n","POS Tags: [('In', 'IN'), ('my', 'PRP$'), ('self', 'NN'), ('is', 'VBZ'), ('present', 'JJ'), ('the', 'DT'), ('reasons', 'NNS'), ('of', 'IN'), ('this', 'DT'), ('statement', 'NN'), (',', ','), ('that', 'WDT'), ('is', 'VBZ'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('problem', 'NN'), ('of', 'IN'), ('the', 'DT'), ('life', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n","Tokens: ['But', 'not', 'all', 'the', 'people', 'and', 'the', 'time', 'is', 'in', 'accord', 'with', 'this', 'problem', ',', 'because', 'any', 'time', 'the', 'person', 'is', 'too', 'according', 'with', 'the', 'make', 'products', '.']\n","POS Tags: [('But', 'CC'), ('not', 'RB'), ('all', 'PDT'), ('the', 'DT'), ('people', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('time', 'NN'), ('is', 'VBZ'), ('in', 'IN'), ('accord', 'NN'), ('with', 'IN'), ('this', 'DT'), ('problem', 'NN'), (',', ','), ('because', 'IN'), ('any', 'DT'), ('time', 'NN'), ('the', 'DT'), ('person', 'NN'), ('is', 'VBZ'), ('too', 'RB'), ('according', 'VBG'), ('with', 'IN'), ('the', 'DT'), ('make', 'NN'), ('products', 'NNS'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Conjunction usage is incorrect\n","=================================================\n","Sentence: Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n","Tokens: ['Thus', 'I', 'agree', 'with', 'this', 'statement', ',', 'because', 'this', 'event', 'is', 'present', 'in', 'my', 'life', 'every', 'day', ',', 'and', 'rappresented', 'the', 'problem', 'with', 'I', 'do', 'fighting', '.']\n","POS Tags: [('Thus', 'RB'), ('I', 'PRP'), ('agree', 'VBP'), ('with', 'IN'), ('this', 'DT'), ('statement', 'NN'), (',', ','), ('because', 'IN'), ('this', 'DT'), ('event', 'NN'), ('is', 'VBZ'), ('present', 'JJ'), ('in', 'IN'), ('my', 'PRP$'), ('life', 'NN'), ('every', 'DT'), ('day', 'NN'), (',', ','), ('and', 'CC'), ('rappresented', 'VBD'), ('the', 'DT'), ('problem', 'NN'), ('with', 'IN'), ('I', 'PRP'), ('do', 'VBP'), ('fighting', 'VBG'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: But to explain all the aspect about this argoment is very inportant to illustre any examples.\n","Tokens: ['But', 'to', 'explain', 'all', 'the', 'aspect', 'about', 'this', 'argoment', 'is', 'very', 'inportant', 'to', 'illustre', 'any', 'examples', '.']\n","POS Tags: [('But', 'CC'), ('to', 'TO'), ('explain', 'VB'), ('all', 'PDT'), ('the', 'DT'), ('aspect', 'NN'), ('about', 'IN'), ('this', 'DT'), ('argoment', 'NN'), ('is', 'VBZ'), ('very', 'RB'), ('inportant', 'JJ'), ('to', 'TO'), ('illustre', 'VB'), ('any', 'DT'), ('examples', 'NNS'), ('.', '.')]\n","Error: Conjunction usage is incorrect\n","=================================================\n","Sentence: The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n","Tokens: ['The', 'television', 'programs', 'that', 'every', 'day', 'introduce', 'in', 'the', 'minds', 'more', 'argoment', ',', 'news', 'and', 'other', 'problem', ',', 'or', 'breaking', 'news', ',', 'is', 'the', 'first', 'actor', 'in', 'this', 'process', '.']\n","POS Tags: [('The', 'DT'), ('television', 'NN'), ('programs', 'NNS'), ('that', 'WDT'), ('every', 'DT'), ('day', 'NN'), ('introduce', 'VB'), ('in', 'IN'), ('the', 'DT'), ('minds', 'NNS'), ('more', 'RBR'), ('argoment', 'JJ'), (',', ','), ('news', 'NN'), ('and', 'CC'), ('other', 'JJ'), ('problem', 'NN'), (',', ','), ('or', 'CC'), ('breaking', 'VBG'), ('news', 'NN'), (',', ','), ('is', 'VBZ'), ('the', 'DT'), ('first', 'JJ'), ('actor', 'NN'), ('in', 'IN'), ('this', 'DT'), ('process', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n","Tokens: ['This', 'opinion', 'rappresented', 'my', 'self', 'in', 'my', 'life', ',', 'because', 'for', 'me', 'the', 'life', 'of', 'all', 'the', 'people', 'is', 'not', 'possible', 'to', 'influence', 'by', 'the', 'activity', 'of', 'any', 'person', '.']\n","POS Tags: [('This', 'DT'), ('opinion', 'NN'), ('rappresented', 'VBD'), ('my', 'PRP$'), ('self', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('life', 'NN'), (',', ','), ('because', 'IN'), ('for', 'IN'), ('me', 'PRP'), ('the', 'DT'), ('life', 'NN'), ('of', 'IN'), ('all', 'PDT'), ('the', 'DT'), ('people', 'NNS'), ('is', 'VBZ'), ('not', 'RB'), ('possible', 'JJ'), ('to', 'TO'), ('influence', 'VB'), ('by', 'IN'), ('the', 'DT'), ('activity', 'NN'), ('of', 'IN'), ('any', 'DT'), ('person', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n","Tokens: ['The', 'society', 'lose', 'the', 'propriety', 'when', 'this', 'problem', 'will', 'rappresent', 'the', 'must', 'argoment', 'of', 'the', 'talk', 'and', 'the', 'life', 'of', 'the', 'people', ',', 'because', 'as', 'very', 'difficult', 'live', 'at', 'a', 'time', 'with', 'this', 'argoment', '.']\n","POS Tags: [('The', 'DT'), ('society', 'NN'), ('lose', 'VBP'), ('the', 'DT'), ('propriety', 'NN'), ('when', 'WRB'), ('this', 'DT'), ('problem', 'NN'), ('will', 'MD'), ('rappresent', 'VB'), ('the', 'DT'), ('must', 'MD'), ('argoment', 'NN'), ('of', 'IN'), ('the', 'DT'), ('talk', 'NN'), ('and', 'CC'), ('the', 'DT'), ('life', 'NN'), ('of', 'IN'), ('the', 'DT'), ('people', 'NNS'), (',', ','), ('because', 'IN'), ('as', 'IN'), ('very', 'RB'), ('difficult', 'JJ'), ('live', 'VBP'), ('at', 'IN'), ('a', 'DT'), ('time', 'NN'), ('with', 'IN'), ('this', 'DT'), ('argoment', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: The my request is that the new politics discuss about this problem.\n","Tokens: ['The', 'my', 'request', 'is', 'that', 'the', 'new', 'politics', 'discuss', 'about', 'this', 'problem', '.']\n","POS Tags: [('The', 'DT'), ('my', 'PRP$'), ('request', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('new', 'JJ'), ('politics', 'NNS'), ('discuss', 'VBP'), ('about', 'IN'), ('this', 'DT'), ('problem', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","Total mistakes in the essay: 29\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package dependency_treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package dependency_treebank is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.parse import DependencyGraph\n","\n","# Download the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('dependency_treebank')\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    print(\"Sentence:\", sentence)\n","\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","    print(\"Tokens:\", tokens)\n","\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","    print(\"POS Tags:\", pos_tags)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if not is_main_sentence_formed_properly(pos_tags):\n","        print(\"Error: Main sentence formation is not proper\")\n","        mistake_count += 1\n","\n","    # Check for missing constituents\n","    if not are_constituents_formed_properly(pos_tags):\n","        print(\"Error: Constituents are not formed properly\")\n","        mistake_count += 1\n","\n","    # Check for subordinating conjunctions\n","    if not is_subordinating_conjunction_correct(pos_tags):\n","        print(\"Error: Subordinating conjunction is used incorrectly\")\n","        mistake_count += 1\n","\n","    # Check for verb agreement and tense consistency\n","    if not is_verb_agreement_and_tense_consistent(pos_tags):\n","        print(\"Error: Verb agreement and tense consistency issue\")\n","        mistake_count += 1\n","\n","    # Check for conjunction usage\n","    if not is_conjunction_usage_correct(pos_tags):\n","        print(\"Error: Conjunction usage is incorrect\")\n","        mistake_count += 1\n","\n","    return mistake_count\n","\n","# Function to check if main sentence formation is proper\n","def is_main_sentence_formed_properly(pos_tags):\n","    # Check if the sentence starts with a valid word\n","    first_word_tag = pos_tags[0][1]\n","    if first_word_tag in ['VB', 'VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Verbs\n","        return False\n","\n","    # Check for negation adverb before the main verb\n","    for i in range(1, len(pos_tags)):\n","        if pos_tags[i][1] == 'VB' and pos_tags[i-1][1] == 'RB' and pos_tags[i-1][0].lower() == 'not':\n","            return False\n","\n","    return True\n","\n","# Function to check if constituents are formed properly\n","def are_constituents_formed_properly(pos_tags):\n","    # Check for missing determiners in noun phrases\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'NN' and (i == 0 or pos_tags[i-1][1] != 'DT'):\n","            return False\n","    return True\n","\n","# Function to check if subordinating conjunction is used correctly\n","def is_subordinating_conjunction_correct(pos_tags):\n","    subordinating_conjunctions = ['when', 'although', 'if', 'because']\n","    for word, tag in pos_tags:\n","        if word.lower() in subordinating_conjunctions:\n","            # Check if the corresponding clause is finite or includes a gerund\n","            if tag not in ['VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Finite verbs or gerunds\n","                return False\n","    return True\n","\n","# Function to check if verb agreement and tense consistency are correct\n","def is_verb_agreement_and_tense_consistent(pos_tags):\n","    for i in range(len(pos_tags)):\n","        word, tag = pos_tags[i]\n","        if tag in ['VBZ', 'VBP', 'VBD', 'VBN']:  # Verbs in non-base form\n","            if i == 0 or (pos_tags[i-1][1] != 'PRP' and pos_tags[i-1][1] != 'NN'):  # Verb is not preceded by a personal pronoun or noun\n","                return False\n","    return True\n","\n","\n","\n","# Function to check if conjunction usage is correct\n","def is_conjunction_usage_correct(pos_tags):\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'CC':  # Conjunction\n","            if i == 0 or i == len(pos_tags) - 1:  # Conjunction appears at the beginning or end of the sentence\n","                return False\n","    return True\n","\n","\n","\n","# # Function to check for plurality agreement of nouns and verbs\n","# def check_plurality_agreement(pos_tags):\n","#     # Initialize variables to track noun and verb plurality\n","#     noun_plurality = None\n","#     verb_plurality = None\n","\n","#     # Check for plurality agreement of nouns and verbs\n","#     for word, tag in pos_tags:\n","#         if tag.startswith('NN'):  # Nouns\n","#             if noun_plurality is None:\n","#                 noun_plurality = tag.endswith('S')\n","#             elif noun_plurality != tag.endswith('S'):\n","#                 return False\n","#         elif tag.startswith('VB'):  # Verbs\n","#             if verb_plurality is None:\n","#                 verb_plurality = tag.endswith('S')\n","#             elif verb_plurality != tag.endswith('S'):\n","#                 return False\n","#     return True\n","\n","# Function to check if there is plural/singular agreement between noun and verb\n","def is_plural_singular_agreement_correct(pos_tags):\n","    # Find the index of the first verb in the sentence\n","    verb_index = next((i for i, (word, tag) in enumerate(pos_tags) if tag.startswith('VB')), None)\n","    if verb_index is not None:\n","        # Find the index of the first noun occurring before the verb\n","        noun_index = next((i for i in range(verb_index) if pos_tags[i][1].startswith('NN')), None)\n","        if noun_index is not None:\n","            # Check if the noun and verb agree in plurality\n","            noun_tag = pos_tags[noun_index][1]\n","            verb_tag = pos_tags[verb_index][1]\n","            if noun_tag.endswith('S') and not verb_tag.endswith('S'):  # Noun is plural, but verb is singular\n","                return False\n","            elif not noun_tag.endswith('S') and verb_tag.endswith('S'):  # Noun is singular, but verb is plural\n","                return False\n","    return True\n","\n","\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        print('=================================================')\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    # Print total mistakes in the essay\n","    print(\"Total mistakes in the essay:\", total_mistakes)\n","\n","# Example usage\n","# essay = \"\"\"\n","# The cat sat on the mat.\n","# Because it was raining.\n","# I went to the store.\n","# Dog not want to play.\n","# \"\"\"\n","essay = ''''This is an important aspect of today time.\n","This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n","Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n","To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n","More people go to this program television to talk about your problem, that is very radicate in my nation.\n","The modern society rappresented the perfect ambient to influenced the minds of all the person.\n","In my self is present the reasons of this statement, that is one of the problem of the life.\n","But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n","Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n","But to explain all the aspect about this argoment is very inportant to illustre any examples.\n","The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n","This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n","The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n","The my request is that the new politics discuss about this problem. '''\n","count_mistakes_in_essay(essay)\n"]},{"cell_type":"code","execution_count":null,"id":"dc599fd8","metadata":{"id":"dc599fd8","outputId":"cc76a712-38bd-4bea-dd22-3ca7cf6f2ddf"},"outputs":[{"name":"stdout","output_type":"stream","text":["=================================================\n","Sentence: 'This is an important aspect of today time.\n","Tokens: [\"'This\", 'is', 'an', 'important', 'aspect', 'of', 'today', 'time', '.']\n","POS Tags: [(\"'This\", 'NN'), ('is', 'VBZ'), ('an', 'DT'), ('important', 'JJ'), ('aspect', 'NN'), ('of', 'IN'), ('today', 'NN'), ('time', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","=================================================\n","Sentence: This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n","Tokens: ['This', 'products', 'rathen', 'are', 'not', 'much', 'better', ',', 'but', 'today', 'is', 'not', 'important', 'the', 'really', 'character', 'of', 'the', 'product', ',', 'but', 'only', 'the', 'money', 'and', 'the', 'client', 'not', 'rappresented', 'the', 'important', 'actor', 'in', 'this', 'process', '.']\n","POS Tags: [('This', 'DT'), ('products', 'NNS'), ('rathen', 'NN'), ('are', 'VBP'), ('not', 'RB'), ('much', 'JJ'), ('better', 'RBR'), (',', ','), ('but', 'CC'), ('today', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('important', 'JJ'), ('the', 'DT'), ('really', 'RB'), ('character', 'NN'), ('of', 'IN'), ('the', 'DT'), ('product', 'NN'), (',', ','), ('but', 'CC'), ('only', 'RB'), ('the', 'DT'), ('money', 'NN'), ('and', 'CC'), ('the', 'DT'), ('client', 'NN'), ('not', 'RB'), ('rappresented', 'VBD'), ('the', 'DT'), ('important', 'JJ'), ('actor', 'NN'), ('in', 'IN'), ('this', 'DT'), ('process', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","Error: Plurality agreement of noun with verb is incorrect\n","=================================================\n","Sentence: Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n","Tokens: ['Every', 'day', 'any', 'people', 'buy', 'same', 'products', 'that', 'is', 'not', 'rappresented', 'the', 'your', 'necessity', ',', 'but', 'is', 'only', 'important', 'buy', 'any', 'product', '.']\n","POS Tags: [('Every', 'DT'), ('day', 'NN'), ('any', 'DT'), ('people', 'NNS'), ('buy', 'VBP'), ('same', 'JJ'), ('products', 'NNS'), ('that', 'WDT'), ('is', 'VBZ'), ('not', 'RB'), ('rappresented', 'VBN'), ('the', 'DT'), ('your', 'PRP$'), ('necessity', 'NN'), (',', ','), ('but', 'CC'), ('is', 'VBZ'), ('only', 'RB'), ('important', 'JJ'), ('buy', 'VB'), ('any', 'DT'), ('product', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n","Tokens: ['To', 'explain', 'this', 'argoment', 'in', 'my', 'nation', ',', 'at', 'the', 'television', ',', 'there', 'is', 'an', 'program', 'that', 'discuss', 'of', 'the', 'problem', 'rappresented', 'by', 'this', '.']\n","POS Tags: [('To', 'TO'), ('explain', 'VB'), ('this', 'DT'), ('argoment', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('nation', 'NN'), (',', ','), ('at', 'IN'), ('the', 'DT'), ('television', 'NN'), (',', ','), ('there', 'EX'), ('is', 'VBZ'), ('an', 'DT'), ('program', 'NN'), ('that', 'WDT'), ('discuss', 'NN'), ('of', 'IN'), ('the', 'DT'), ('problem', 'NN'), ('rappresented', 'VBN'), ('by', 'IN'), ('this', 'DT'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: More people go to this program television to talk about your problem, that is very radicate in my nation.\n","Tokens: ['More', 'people', 'go', 'to', 'this', 'program', 'television', 'to', 'talk', 'about', 'your', 'problem', ',', 'that', 'is', 'very', 'radicate', 'in', 'my', 'nation', '.']\n","POS Tags: [('More', 'JJR'), ('people', 'NNS'), ('go', 'VBP'), ('to', 'TO'), ('this', 'DT'), ('program', 'NN'), ('television', 'NN'), ('to', 'TO'), ('talk', 'VB'), ('about', 'IN'), ('your', 'PRP$'), ('problem', 'NN'), (',', ','), ('that', 'WDT'), ('is', 'VBZ'), ('very', 'RB'), ('radicate', 'JJ'), ('in', 'IN'), ('my', 'PRP$'), ('nation', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","Error: Plurality agreement of noun with verb is incorrect\n","=================================================\n","Sentence: The modern society rappresented the perfect ambient to influenced the minds of all the person.\n","Tokens: ['The', 'modern', 'society', 'rappresented', 'the', 'perfect', 'ambient', 'to', 'influenced', 'the', 'minds', 'of', 'all', 'the', 'person', '.']\n","POS Tags: [('The', 'DT'), ('modern', 'JJ'), ('society', 'NN'), ('rappresented', 'VBD'), ('the', 'DT'), ('perfect', 'JJ'), ('ambient', 'NN'), ('to', 'TO'), ('influenced', 'VB'), ('the', 'DT'), ('minds', 'NNS'), ('of', 'IN'), ('all', 'PDT'), ('the', 'DT'), ('person', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","=================================================\n","Sentence: In my self is present the reasons of this statement, that is one of the problem of the life.\n","Tokens: ['In', 'my', 'self', 'is', 'present', 'the', 'reasons', 'of', 'this', 'statement', ',', 'that', 'is', 'one', 'of', 'the', 'problem', 'of', 'the', 'life', '.']\n","POS Tags: [('In', 'IN'), ('my', 'PRP$'), ('self', 'NN'), ('is', 'VBZ'), ('present', 'JJ'), ('the', 'DT'), ('reasons', 'NNS'), ('of', 'IN'), ('this', 'DT'), ('statement', 'NN'), (',', ','), ('that', 'WDT'), ('is', 'VBZ'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('problem', 'NN'), ('of', 'IN'), ('the', 'DT'), ('life', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n","Tokens: ['But', 'not', 'all', 'the', 'people', 'and', 'the', 'time', 'is', 'in', 'accord', 'with', 'this', 'problem', ',', 'because', 'any', 'time', 'the', 'person', 'is', 'too', 'according', 'with', 'the', 'make', 'products', '.']\n","POS Tags: [('But', 'CC'), ('not', 'RB'), ('all', 'PDT'), ('the', 'DT'), ('people', 'NNS'), ('and', 'CC'), ('the', 'DT'), ('time', 'NN'), ('is', 'VBZ'), ('in', 'IN'), ('accord', 'NN'), ('with', 'IN'), ('this', 'DT'), ('problem', 'NN'), (',', ','), ('because', 'IN'), ('any', 'DT'), ('time', 'NN'), ('the', 'DT'), ('person', 'NN'), ('is', 'VBZ'), ('too', 'RB'), ('according', 'VBG'), ('with', 'IN'), ('the', 'DT'), ('make', 'NN'), ('products', 'NNS'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Conjunction usage is incorrect\n","Error: Plurality agreement of noun with verb is incorrect\n","=================================================\n","Sentence: Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n","Tokens: ['Thus', 'I', 'agree', 'with', 'this', 'statement', ',', 'because', 'this', 'event', 'is', 'present', 'in', 'my', 'life', 'every', 'day', ',', 'and', 'rappresented', 'the', 'problem', 'with', 'I', 'do', 'fighting', '.']\n","POS Tags: [('Thus', 'RB'), ('I', 'PRP'), ('agree', 'VBP'), ('with', 'IN'), ('this', 'DT'), ('statement', 'NN'), (',', ','), ('because', 'IN'), ('this', 'DT'), ('event', 'NN'), ('is', 'VBZ'), ('present', 'JJ'), ('in', 'IN'), ('my', 'PRP$'), ('life', 'NN'), ('every', 'DT'), ('day', 'NN'), (',', ','), ('and', 'CC'), ('rappresented', 'VBD'), ('the', 'DT'), ('problem', 'NN'), ('with', 'IN'), ('I', 'PRP'), ('do', 'VBP'), ('fighting', 'VBG'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: But to explain all the aspect about this argoment is very inportant to illustre any examples.\n","Tokens: ['But', 'to', 'explain', 'all', 'the', 'aspect', 'about', 'this', 'argoment', 'is', 'very', 'inportant', 'to', 'illustre', 'any', 'examples', '.']\n","POS Tags: [('But', 'CC'), ('to', 'TO'), ('explain', 'VB'), ('all', 'PDT'), ('the', 'DT'), ('aspect', 'NN'), ('about', 'IN'), ('this', 'DT'), ('argoment', 'NN'), ('is', 'VBZ'), ('very', 'RB'), ('inportant', 'JJ'), ('to', 'TO'), ('illustre', 'VB'), ('any', 'DT'), ('examples', 'NNS'), ('.', '.')]\n","Error: Conjunction usage is incorrect\n","=================================================\n","Sentence: The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n","Tokens: ['The', 'television', 'programs', 'that', 'every', 'day', 'introduce', 'in', 'the', 'minds', 'more', 'argoment', ',', 'news', 'and', 'other', 'problem', ',', 'or', 'breaking', 'news', ',', 'is', 'the', 'first', 'actor', 'in', 'this', 'process', '.']\n","POS Tags: [('The', 'DT'), ('television', 'NN'), ('programs', 'NNS'), ('that', 'WDT'), ('every', 'DT'), ('day', 'NN'), ('introduce', 'VB'), ('in', 'IN'), ('the', 'DT'), ('minds', 'NNS'), ('more', 'RBR'), ('argoment', 'JJ'), (',', ','), ('news', 'NN'), ('and', 'CC'), ('other', 'JJ'), ('problem', 'NN'), (',', ','), ('or', 'CC'), ('breaking', 'VBG'), ('news', 'NN'), (',', ','), ('is', 'VBZ'), ('the', 'DT'), ('first', 'JJ'), ('actor', 'NN'), ('in', 'IN'), ('this', 'DT'), ('process', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n","Tokens: ['This', 'opinion', 'rappresented', 'my', 'self', 'in', 'my', 'life', ',', 'because', 'for', 'me', 'the', 'life', 'of', 'all', 'the', 'people', 'is', 'not', 'possible', 'to', 'influence', 'by', 'the', 'activity', 'of', 'any', 'person', '.']\n","POS Tags: [('This', 'DT'), ('opinion', 'NN'), ('rappresented', 'VBD'), ('my', 'PRP$'), ('self', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('life', 'NN'), (',', ','), ('because', 'IN'), ('for', 'IN'), ('me', 'PRP'), ('the', 'DT'), ('life', 'NN'), ('of', 'IN'), ('all', 'PDT'), ('the', 'DT'), ('people', 'NNS'), ('is', 'VBZ'), ('not', 'RB'), ('possible', 'JJ'), ('to', 'TO'), ('influence', 'VB'), ('by', 'IN'), ('the', 'DT'), ('activity', 'NN'), ('of', 'IN'), ('any', 'DT'), ('person', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n","Tokens: ['The', 'society', 'lose', 'the', 'propriety', 'when', 'this', 'problem', 'will', 'rappresent', 'the', 'must', 'argoment', 'of', 'the', 'talk', 'and', 'the', 'life', 'of', 'the', 'people', ',', 'because', 'as', 'very', 'difficult', 'live', 'at', 'a', 'time', 'with', 'this', 'argoment', '.']\n","POS Tags: [('The', 'DT'), ('society', 'NN'), ('lose', 'VBP'), ('the', 'DT'), ('propriety', 'NN'), ('when', 'WRB'), ('this', 'DT'), ('problem', 'NN'), ('will', 'MD'), ('rappresent', 'VB'), ('the', 'DT'), ('must', 'MD'), ('argoment', 'NN'), ('of', 'IN'), ('the', 'DT'), ('talk', 'NN'), ('and', 'CC'), ('the', 'DT'), ('life', 'NN'), ('of', 'IN'), ('the', 'DT'), ('people', 'NNS'), (',', ','), ('because', 'IN'), ('as', 'IN'), ('very', 'RB'), ('difficult', 'JJ'), ('live', 'VBP'), ('at', 'IN'), ('a', 'DT'), ('time', 'NN'), ('with', 'IN'), ('this', 'DT'), ('argoment', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Subordinating conjunction is used incorrectly\n","Error: Verb agreement and tense consistency issue\n","=================================================\n","Sentence: The my request is that the new politics discuss about this problem.\n","Tokens: ['The', 'my', 'request', 'is', 'that', 'the', 'new', 'politics', 'discuss', 'about', 'this', 'problem', '.']\n","POS Tags: [('The', 'DT'), ('my', 'PRP$'), ('request', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('new', 'JJ'), ('politics', 'NNS'), ('discuss', 'VBP'), ('about', 'IN'), ('this', 'DT'), ('problem', 'NN'), ('.', '.')]\n","Error: Constituents are not formed properly\n","Error: Verb agreement and tense consistency issue\n","Length: 14\n","Total mistakes in the essay: 32\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package tagsets to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package tagsets is already up-to-date!\n","[nltk_data] Downloading package dependency_treebank to\n","[nltk_data]     /Users/shwetaparihar/nltk_data...\n","[nltk_data]   Package dependency_treebank is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.parse import DependencyGraph\n","\n","# Download the necessary resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('tagsets')\n","nltk.download('dependency_treebank')\n","\n","# Function to check syntactic well-formedness of a sentence\n","def check_syntactic_wellformedness(sentence):\n","    print(\"Sentence:\", sentence)\n","\n","    # Tokenize the sentence\n","    tokens = nltk.word_tokenize(sentence)\n","    print(\"Tokens:\", tokens)\n","\n","    # Perform Part-of-Speech tagging\n","    pos_tags = nltk.pos_tag(tokens)\n","    print(\"POS Tags:\", pos_tags)\n","\n","    # Convert POS tags to string format compatible with DependencyGraph\n","    dep_str = \"\\n\".join([f\"{i+1}\\t{token}\\t{tag}\\t{idx}\\t{tag}\\t_\\t{head}\\t_\\t_\\t_\"\n","                         for i, ((token, tag), (idx, head)) in enumerate(zip(pos_tags, enumerate(range(1, len(pos_tags) + 1))))])\n","\n","    # Perform dependency parsing\n","    parser = DependencyGraph(dep_str, top_relation_label='root')\n","\n","    # Counter for mistakes\n","    mistake_count = 0\n","\n","    # Check criteria for main sentence formation\n","    if not is_main_sentence_formed_properly(pos_tags):\n","        print(\"Error: Main sentence formation is not proper\")\n","        mistake_count += 1\n","\n","    # Check for missing constituents\n","    if not are_constituents_formed_properly(pos_tags):\n","        print(\"Error: Constituents are not formed properly\")\n","        mistake_count += 1\n","\n","    # Check for subordinating conjunctions\n","    if not is_subordinating_conjunction_correct(pos_tags):\n","        print(\"Error: Subordinating conjunction is used incorrectly\")\n","        mistake_count += 1\n","\n","    # Check for verb agreement and tense consistency\n","    if not is_verb_agreement_and_tense_consistent(pos_tags):\n","        print(\"Error: Verb agreement and tense consistency issue\")\n","        mistake_count += 1\n","\n","    # Check for conjunction usage\n","    if not is_conjunction_usage_correct(pos_tags):\n","        print(\"Error: Conjunction usage is incorrect\")\n","        mistake_count += 1\n","\n","    # Check for plurality agreement of noun with verb\n","    if not is_plural_singular_agreement_correct(pos_tags):\n","        print(\"Error: Plurality agreement of noun with verb is incorrect\")\n","        mistake_count += 1\n","\n","    return mistake_count\n","\n","# Function to check if main sentence formation is proper\n","def is_main_sentence_formed_properly(pos_tags):\n","    # Check if the sentence starts with a valid word\n","    first_word_tag = pos_tags[0][1]\n","    if first_word_tag in ['VB', 'VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Verbs\n","        return False\n","\n","    # Check for negation adverb before the main verb\n","    for i in range(1, len(pos_tags)):\n","        if pos_tags[i][1] == 'VB' and pos_tags[i-1][1] == 'RB' and pos_tags[i-1][0].lower() == 'not':\n","            return False\n","\n","    return True\n","\n","# Function to check if constituents are formed properly\n","def are_constituents_formed_properly(pos_tags):\n","    # Check for missing determiners in noun phrases\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'NN' and (i == 0 or pos_tags[i-1][1] != 'DT'):\n","            return False\n","    return True\n","\n","# Function to check if subordinating conjunction is used correctly\n","def is_subordinating_conjunction_correct(pos_tags):\n","    subordinating_conjunctions = ['when', 'although', 'if', 'because']\n","    for word, tag in pos_tags:\n","        if word.lower() in subordinating_conjunctions:\n","            # Check if the corresponding clause is finite or includes a gerund\n","            if tag not in ['VBP', 'VBZ', 'VBG', 'VBD', 'VBN']:  # Finite verbs or gerunds\n","                return False\n","    return True\n","\n","# Function to check if verb agreement and tense consistency are correct\n","def is_verb_agreement_and_tense_consistent(pos_tags):\n","    for i in range(len(pos_tags)):\n","        word, tag = pos_tags[i]\n","        if tag in ['VBZ', 'VBP', 'VBD', 'VBN']:  # Verbs in non-base form\n","            if i == 0 or (pos_tags[i-1][1] != 'PRP' and pos_tags[i-1][1] != 'NN'):  # Verb is not preceded by a personal pronoun or noun\n","                return False\n","    return True\n","\n","# Function to check if conjunction usage is correct\n","def is_conjunction_usage_correct(pos_tags):\n","    for i in range(len(pos_tags)):\n","        if pos_tags[i][1] == 'CC':  # Conjunction\n","            if i == 0 or i == len(pos_tags) - 1:  # Conjunction appears at the beginning or end of the sentence\n","                return False\n","    return True\n","\n","# Function to check if there is plural/singular agreement between noun and verb\n","def is_plural_singular_agreement_correct(pos_tags):\n","    # Find the index of the first verb in the sentence\n","    verb_index = next((i for i, (word, tag) in enumerate(pos_tags) if tag.startswith('VB')), None)\n","    if verb_index is not None:\n","        # Find the index of the first noun occurring before the verb\n","        noun_index = next((i for i in range(verb_index) if pos_tags[i][1].startswith('NN')), None)\n","        if noun_index is not None:\n","            # Check if the noun and verb agree in plurality\n","            noun_tag = pos_tags[noun_index][1]\n","            verb_tag = pos_tags[verb_index][1]\n","            if noun_tag.endswith('S') and not verb_tag.endswith('S'):  # Noun is plural, but verb is singular\n","                return False\n","            elif not noun_tag.endswith('S') and verb_tag.endswith('S'):  # Noun is singular, but verb is plural\n","                return False\n","    return True\n","\n","# Function to count mistakes in an essay\n","def count_mistakes_in_essay(essay):\n","    # Tokenize the essay into sentences\n","    sentences = nltk.sent_tokenize(essay)\n","\n","    # Counter for total mistakes in the essay\n","    total_mistakes = 0\n","\n","    # Iterate through each sentence\n","    for sentence in sentences:\n","        print('=================================================')\n","        # Check syntactic well-formedness of the sentence\n","        mistakes_in_sentence = check_syntactic_wellformedness(sentence)\n","\n","        # Update total mistake count\n","        total_mistakes += mistakes_in_sentence\n","\n","    # Print total sentences in the essay\n","    print(\"Length:\", len(sentences))\n","\n","    # Print total mistakes in the essay\n","    print(\"Total mistakes in the essay:\", total_mistakes)\n","\n","\n","essay = ''''This is an important aspect of today time.\n","This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n","Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n","To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n","More people go to this program television to talk about your problem, that is very radicate in my nation.\n","The modern society rappresented the perfect ambient to influenced the minds of all the person.\n","In my self is present the reasons of this statement, that is one of the problem of the life.\n","But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n","Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n","But to explain all the aspect about this argoment is very inportant to illustre any examples.\n","The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n","This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n","The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n","The my request is that the new politics discuss about this problem. '''\n","\n","count_mistakes_in_essay(essay)\n"]},{"cell_type":"code","execution_count":null,"id":"a06f9403","metadata":{"id":"a06f9403"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}